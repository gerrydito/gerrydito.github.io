{
  "hash": "2f1f4561f7891c1a765e07c9719c6279",
  "result": {
    "markdown": "---\ntitle: \"Algoritme Expectation-Maximization (EM) menggunakan R\"\ndate: 11-19-2021\nauthor: Gerry Alfa Dito\ncategories: \n      - R Programming\n      - Computational Statistics\ndraft: false\nimage: post-image.jpg\n---\n\n\n\n## Algoritme EM\n\n**Algoritme EM** adalah cara untuk menghitung estimasi parameter model menggunakan Metode **MLE (Maksimum Likelihood Estimation)** ketika data yang kita **tidak lengkap**, memiliki **missing data**, atau memiliki variabel laten (latent variable) yang tak teramati. Secara singkat EM bisa diartikan sebagai metode untuk iteratif yang bisa mendekati Likelihood function. **Metode MLE** memiliki hanya bisa mengestimasi parameter dengan baik jika **data** yang kita miliki **tidak lengkap**. Algoritme EM bekerja dengan memilih **nilai acak** untuk titik data yang tidak lengkap, dan menggunakan **nilai acak** tersebut untuk mengestimasi data yang tidak lengkap. \n\n\nMisalkan $X=(X_{1},X_{2},\\ldots,X_{n_{1}})$ merupakan sampel yang teramati (observed) dan $Z=(Z_{1},Z_{2},\\ldots,Z_{n_{2}})$ merupakan sampel yang tak teramati (unobserved) dengan $n=n_{1}+n_{2}$. Asumsikan bahwa $X_{i}$ i.i.d dengan pdf $f(x|\\theta)$ dan $Z_{j}$ serta $X_{i}$ saling lepas. Misalkan $g(x|\\theta)$ merupakan **joint pdf** dari $X$ dan $h(x,z|\\theta)$ merupakan **joint pdf** antara **observed** dan **unobserved**. **Conditional pdf** dari **unobserved** adalah\n\n$$\nf(z|\\theta,x)=\\frac{h(x,z|\\theta)}{g(x|\\theta)}\n$$\nFungsi observed likelihood didefinisikan $L(\\theta|x)=g(x|\\theta)$ dan fungsi complete likelihood didefinisikan $L^{c}(\\theta|x,z)=h(x,z|\\theta)$\n\n\nTahap-tahap dalam Algoritme EM dapat ditulis sebagai berikut\n\n1. Isi data yang tak lengkap tersebut dengan suatu nilai estimasi yang didapatkan dari nilai Ekspetasi fungsi log-Likelihood\n\n$$\nQ(\\theta|\\hat{\\theta}^{(m)})=\\text{E}_{\\hat{\\theta}^{(m)}}\\left[\\log{L^{c}(\\theta|x,z)}|\\hat{\\theta}^{(m)},x\\right]=\\int_{-\\infty}^{\\infty}\\log{[h(x,z|\\theta)]}f(z|\\hat{\\theta}^{(m)},x)\n$$\n\nTahap 1 ini sering disebut dengan **Tahap Expectation** atau **Tahap-E**\n\n\n2. Dari tahap 1 kita sudah memperoleh **data lengkap**, selanjutnya **estimasi parameter** menggunakan data lengkap tersebut. Estimasi parameter dilakukan dengan menerapkan metode MLE pada fungsi $Q(\\theta|\\hat{\\theta}^{(m)})$ sebagai berikut:\n\n$$\n\\hat{\\theta}^{(m+1)}= \\arg \\max{Q(\\theta|\\hat{\\theta}^{(m)})}\n$$\nTahap 2 ini sering disebut dengan **Tahap Maximization** atau **Tahap-M**\n\n3. Gunakan parameter hasil estimasi pada tahap 2 untuk mendapatkan nilai estimasi yang baru\n\n4. Gunakan nilai estimasi yang baru pada tahap 3 untuk mendapatkan estimasi parameter yang baru\n\nLakukan langkah 3 dan 4 sampai konvergen\n\n\n## Penerapan Algoritme EM\n\nBerikut adalah beberapa penerapan EM-Algorithm\n\n1. Missing Data Problems\n2. Grouped Data Problems\n3. Truncated and Censored Data Problems\n4. Latent Variable Estimation\n5. Mixtures Model\n\n\n\n\n### Ilustrasi 1\n\nRao (1973) melakukan pembagian secara acak 197 hewan menjadi 4 kategori berdasarkan phenotypes sedemikian sehingga:\n\n$$\n\\boldsymbol{y} = (y_{1}, y_{2}, y_{3}, y_{4})^{T} = (100, 12, 18, 29)^{T}\n$$\n\ndengan peluang setiap kategori\n\n$$\n\\left(p_{1}={\\frac{1}{2}+\\frac{\\theta}{4},p_{2}=\\frac{1-\\theta}{4},p_{3}=\\frac{1-\\theta}{4},p_{4}=\\frac{\\theta}{4}}\\right)\n$$\n\nsehingga $\\boldsymbol{y}\\sim \\text{Multinomial}(p_{1},p_{2},p_{3},p_{4})$. Fungsi kepekatan peluang (fkp) atau probability density function (pdf) dari $\\boldsymbol{y}$ adalah\n\n$$\ng(\\boldsymbol{y}|\\theta) = \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\n\n\nJika peneliti menambahkan satu kategori lagi dengan memecah kategori pertama menjadi 2 kategori sedemikian sehingga\n\n$$\\boldsymbol{x} = (x_{1},x_{2},x_{3},x_{4},x_{5})^{T}$$\n\ndimana $x_{1}+x_{2}=y_{1},x_{3}=y_{2},x_{4}=y_{3},x_{5}=y_{4}$dengan peluang setiap kategori menjadi\n\n\n$$\n\\left(\\frac{1}{2},\\frac{\\theta}{4},\\frac{1-\\theta}{4},\\frac{1-\\theta}{4},\\frac{\\theta}{4}\\right)\n$$\n\n\nsehingga $\\boldsymbol{x}\\sim \\text{Multinomial}(p_{1},p_{2},p_{3},p_{4},p_{5})$. Fungsi kepekatan peluang (fkp) atau probability density function (pdf) dari $\\boldsymbol{x}$ adalah\n\n\n$$\nf(\\boldsymbol{x}|\\theta) = \\frac{x_{1}+x_{2}+x_{3}+x_{4}+x_{5}}{x_{1}! x_{2}! x_{3}! x_{4}! x_{5}!} \\left(\\frac{1}{2}\\right) ^{x_{1}} \\left(\\frac{\\theta}{4} \\right) ^{x_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{x_{3}} \\left(\\frac{1-\\theta}{4}\\right)^{x_{4}} \\left(\\frac{\\theta}{4}\\right)^{x_{5}}\n$$\n\nJika diketahui fungsi log-likelihood bagi $y$ adalah\n\n$$\n\\log{L(\\theta|y)} = c+y_{1} \\log{(2+\\theta)} + (y_{2} + y_{3}) \\log{(1-\\theta)} + y_{4} \\log{\\theta}\n$$\ndan fungsi fungsi log-likelihood bagi $x$ adalah\n\n\n$$\n\\log{L(\\theta|x)} = c+x_{1}\\log{\\left(\\frac{1}{2}\\right)}+(x_2+ x_5)\\log{\\theta} + (x_3+x_4) \\log{ (1-\\theta)} \n$$\n\na. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $y$\nb. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $x$\nc. Hitunglah estimasi $x_1$,$x_2$ dan $\\hat{\\theta}$ menggunakan Algoritme EM dengan toleransi $10^{-7}$!\n\n### Pembahasan Ilustrasi 1\n\n\na. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $y$\n\nFungsi Likelihood bagi $y$ \n\n$$\nL(\\theta|\\boldsymbol{y}) = g(\\boldsymbol{y}|\\theta)\n$$\n$$\nL(\\theta|\\boldsymbol{y}) = \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\nfungsi log-likelihood bagi $y$\n\n$$\n\\log{L(\\theta|y)} = \\log{\\left( \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!}\\ \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}} \\right)}\n$$\n\n$$\n\\log{L(\\theta|y)} = \\log{\\left( \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\right)} + \\log{\\left(\\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right)  ^{y_{1}}\\right)} + \\log{\\left(\\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\right)} + \\log{\\left(\\left(\\frac{1-\\theta}{4}\\right)^{y_{3}}\\right)} + \\log{\\left(\\left(\\frac{\\theta}{4}\\right)^{y_{4}}\\right)} \n$$\nkita misalkan bagian yang tidak ada unsur $\\theta$ sebagai $c$ atau konstanta\n\n\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right)} + y_{2} \\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{3}\\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{4}\\log{\\left(\\frac{\\theta}{4}\\right)} \n$$\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(\\frac{2+\\theta}{4} \\right)} + y_{2} \\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{3}\\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{4}\\log{\\left(\\frac{\\theta}{4}\\right)} \n$$\n\n\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(2+\\theta \\right)}- y_{1} \\log{\\left(4 \\right)} + y_{2} \\log{\\left(1-\\theta\\right)}-y_{2} \\log{\\left({4}\\right)} + y_{3}\\log{\\left({1-\\theta}\\right)}-y_{3}\\log{\\left({4}\\right)} + y_{4}\\log{\\left(\\theta\\right)} - y_{4}\\log{\\left(4\\right)} \n$$\n\nkemudian kita gabungan semua bagian yang tidak mengandung $\\theta$ menjadi $c$ atau konstanta\n\n\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(2+\\theta \\right)} + y_{2} \\log{\\left(1-\\theta\\right)} + y_{3}\\log{\\left({1-\\theta}\\right)} + y_{4}\\log{\\left(\\theta\\right)}  \n$$\n\nb. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $x$\n\nSilahkan kerjakan sebagai latihan\n\n\nc. Hitunglah estimasi $x_1$,$x_2$ dan $\\hat{\\theta}$ menggunakan Algoritme EM dengan toleransi $10^{-7}$!\n\n1. Isi data yang tak lengkap tersebut dengan suatu nilai estimasi yang didapatkan dari nilai Ekspetasi fungsi log-Likelihood\n\n$$\nQ(\\theta|\\hat{\\theta}^{(m)})=\\text{E}_{\\hat{\\theta}^{(m)}}\\left[\\log{L^{c}(\\theta|x,z)}|\\hat{\\theta}^{(m)},x\\right]\n$$\n\nTahap 1 ini sering disebut dengan **Tahap Expectation** atau **Tahap-E**\n\n\nPada tahap 1 ini hal pertama yang kita lakukan adalah menentukan fungsi **complete log-likelihood** $\\log{L^{c}(\\theta|x,z)}$ yang bisa kita ambil dari fungsi **log-likelihood** bagi $x$\n\n$$\n\\log{L(\\theta|x)} = c+x_{1}\\log{\\left(\\frac{1}{2}\\right)}+(x_2+ x_5)\\log{\\theta} + (x_3+x_4) \\log{ (1-\\theta)} \n$$\nkarena di dalam fungsi ini terdapat data unobserved $x_{1}$ dan $x_{2}$ serta data observed $x_{3},x_{4},x_{5}$ sehingga jika digabungkan akan menjadi fungsi **complete log-likelihood**\n\nUntuk mempermudah perhitungan kita misalkan $z_{1}=x_{1}$ dan $z_{1}=x_{2}$, yang mana $x_{1}$ dan $x_{2}$ merupakan data unobserved. Sehingga $\\boldsymbol{z}=(z_{1},z_{2})$. Kemudian, kita tahu bahwa $x_{3}=y_{2},x_{4}=y_{3},x_{5}=y_{4}$ sehingga kita rubah simbol $x$ menjadi $y$. Jadi fungsi **complete log-likelihood** adalah sebagai berikut\n\n$$\n\\log{L^{c}(\\theta|y,z}) = c+z_{1}\\log{\\left(\\frac{1}{2}\\right)}+(z_2+ y_4)\\log{\\theta} + (y_2+y_3) \\log{ (1-\\theta)}  \n$$\n\nkemudian kita hitung fungsi $Q(\\theta|\\hat{\\theta}^{(0)}$\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})=\\text{E}_{\\hat{\\theta}^{(0)}}[\\log{L^{c}(\\theta|y,z)}|\\hat{\\theta}^{(0)},y] \n$$\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= \\text{E}_{\\hat{\\theta}^{(0)}}\\left[c+z_{1}\\log{\\left(\\frac{1}{2}\\right)}+(z_2+ y_4)\\log{\\theta} + (y_2+y_3) \\log{ (1-\\theta)} |\\hat{\\theta}^{(0)},y \\right]\n$$\n\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= \\text{E}_{\\hat{\\theta}^{(0)}}\\left[c|\\hat{\\theta}^{(0)},y\\right]+\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\log{\\left(\\frac{1}{2}\\right)}|\\hat{\\theta}^{(0)},y\\right]+\\text{E}_{\\hat{\\theta}^{(0)}}\\left[(z_2+ y_4)|\\hat{\\theta}^{(0)},y\\right]\\log{\\theta} + \\text{E}_{\\hat{\\theta}^{(0)}}\\left[(y_2+ y_3)|\\hat{\\theta}^{(0)},y\\right] \\log{(1-\\theta)} \n$$\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= 0+\\log{\\left(\\frac{1}{2}\\right)}\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}|\\hat{\\theta}^{(0)},y \\right]+\\left(\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= \\log{\\left(\\frac{1}{2}\\right)}\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y]+\\left(\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n\nUntuk memperoleh nilai dari $\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y]$ dan $\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]$, kita perlu tahu terlebih dahulu tentang distribusi dari $\\boldsymbol{z}=(z_{1},z_{2})$. Karena $\\boldsymbol{z}=(z_{1},z_{2})$ merupakan data unobserved maka kita bisa mendapatkan pdf dari $\\boldsymbol{z}$ dengan\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{h(\\boldsymbol{y},\\boldsymbol{z}|\\theta)}{g(\\boldsymbol{y}|\\theta)}\n$$\ndengan \n$$\nh(\\boldsymbol{x},\\boldsymbol{z}|\\theta)=L^{c}(\\theta|\\boldsymbol{y},\\boldsymbol{z} )=  \\frac{z_{1}+z_{2}+y_{2}+y_{3}+y_{4}}{z_{1}! z_{2}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\nyang merupakan fungsi **complete likelihood**. Kemudian\n\n$$\ng(\\boldsymbol{y}|\\theta)=L(\\theta|\\boldsymbol{y})=\\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\nyang merupakan fungsi **observed likelihood**. Jadi diperoleh\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{(z_{1}+z_{2}+y_{2}+y_{3}+y_{4})!}{z_{1}! z_{2}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}{\\frac{(y_{1}+y_{2}+y_{3}+y_{4})!}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}\n$$\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{n!}{z_{1}! z_{2}! y_{2}! y_{3}! y_{4}!}  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}{\\frac{n!}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}\n$$\n\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{1}{z_{1}! z_{2}! }  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} }{\\frac{1}{y_{1}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}}}\n$$\n\nkarena $z_{1}+z_{2}=y_{1}$ maka\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{y_{1}!}{z_{1}! z_{2}! }  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} }{ \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{z_{1}+z_{2}}}\n$$\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{y_{1}!}{z_{1}! z_{2}! }  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} }{ \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right)^{z_{1}}  \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{z_{2}}}\n$$\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! z_{2}! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\n\n\n\n\nBerdasarkan hasil diatas, kita dapat memperoleh pdf dari $z_{1}$ dan $z_{2}$ dengan memanfaatkan $z_{1}+z_{2}=y_{1}$. \n\n\nUntuk pdf $z_{1}$\n\n\n$$\nf(z_{1}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! (y_{1}-z_{1})! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(\\frac{\\frac{\\theta}{4}+\\frac{1}{2}-\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{y_{1}-z_{1}}\n$$\n$$\nf(z_{1}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! (y_{1}-z_{1})! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(\\frac{\\frac{1}{2}+\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }   -\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{y_{1}-z_{1}}\n$$\n$$\nf(z_{1}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! (y_{1}-z_{1})! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(1   -\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{y_{1}-z_{1}}\n$$\n\nsehingga $z_{1}$ memiliki distribusi $\\text{Binomial}\\left(y_{1},\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)$\n\n\nKemudian untuk pdf $z_{2}$\n\n$$\nf(z_2|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{(y_{1}-z_{2})! z_{2}! } \\left(\\frac{  \\frac{1}{2}+\\frac{\\theta}{4}-\\frac{\\theta}{4}  }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{y_{1}-z_{2}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\n$$\nf(z_2|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{(y_{1}-z_{2})! z_{2}! } \\left(\\frac{  \\frac{1}{2}+\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} } - \\frac{\\frac{\\theta}{4}  }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{y_{1}-z_{2}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\n\n$$\nf(z_2|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{(y_{1}-z_{2})! z_{2}! } \\left(1 - \\frac{\\frac{\\theta}{4}  }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{y_{1}-z_{2}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\nsehingga $z_{2}$ memiliki distribusi $\\text{Binomial}\\left(y_{1},\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)$\n\n\n**Ingat** bahwa jika $X \\sim \\text{Binomial}(n,p)$ maka nilai ekspetasinya adalah\n\n$$\n\\text{E}(X)=np\n$$\n\nsehingga \n\n$$\n\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y] = y_{1}\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\ndan\n\n\n$$\n\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]=y_{1}\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\nuntuk memudahkan penulisan kita misalkan \n\n$$\n\\hat{z}_{1} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y] = y_{1}\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\nkarena $y_{1}=100$ maka\n\n$$\n\\hat{z}_{1} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y] = 100\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\ndan \n\n$$\n\\hat{z}_{2} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]=y_{1}\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\nkarena $y_{1}=100$ maka\n\n$$\n\\hat{z}_{2} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]=100\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\njadi\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})=\\log{\\left(\\frac{1}{2}\\right)}\\hat{z}_{1}+\\left(\\hat{z}_{2}+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n\n\n2. Dari langkah 1 kita sudah memperoleh **data lengkap**, selanjutnya **estimasi parameter** menggunakan data lengkap tersebut. Estimasi parameter dilakukan dengan menerapkan metode MLE pada fungsi $Q(\\theta|\\hat{\\theta}^{(m)})$ sebagai berikut:\n\n$$\n\\hat{\\theta}^{(m+1)}= \\arg \\max{Q(\\theta|\\hat{\\theta}^{(m)})}\n$$\nTahap 2 ini sering disebut dengan **Tahap Maximization** atau **Tahap-M**\n\nBerdasarkan Tahap 1 diperoleh\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})=\\log{\\left(\\frac{1}{2}\\right)}\\hat{z}_{1}+\\left(\\hat{z}_{2}+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n\nKemudian, kita akan memperoleh $\\hat{\\theta}^{(m)}$ dengan memaksimumkan $Q(\\theta|\\hat{\\theta}^{(0)})$ \n\n$$\n\\hat{\\theta}^{(1)}= \\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})}\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{d\\space Q(\\theta|\\hat{\\theta}^{(0)})}{d\\space \\theta}=0\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{d\\space \\log{\\left(\\frac{1}{2}\\right)}\\hat{z}_{1}+\\left(\\hat{z}_{2}+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} }{d\\space \\theta}=0\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff 0 +\\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{{\\theta}} + \\frac{(y_2+ y_3)}{(1-\\theta)} =0\n$$\n\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{{\\theta}} - \\frac{(y_2+ y_3)}{(1-\\theta)} =0\n$$\n\n\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{{\\theta}} = \\frac{(y_2+ y_3)}{(1-\\theta)}\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{{\\theta}}{\\left(\\hat{z}_{2}+ y_4\\right)} = \\frac{(1-\\theta)}{(y_2+ y_3)}\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{{\\theta}}{(1-\\theta)} = \\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{(y_2+ y_3)}\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3)= \\left(\\hat{z}_{2}+ y_4\\right)(1-\\theta)\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3)= \\left(\\hat{z}_{2}+ y_4\\right)-\\theta\\left(\\hat{z}_{2}+ y_4\\right)\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3)+\\theta\\left(\\hat{z}_{2}+ y_4\\right)= \\left(\\hat{z}_{2}+ y_4\\right)\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3+\\hat{z}_{2}+ y_4)= \\left(\\hat{z}_{2}+ y_4\\right)\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\hat{\\theta}= \\frac{\\hat{z}_{2}+ y_4}{y_2+ y_3+\\hat{z}_{2}+ y_4}\n$$\njadi\n\n$$\n\\hat{\\theta}^{(1)}= \\frac{\\hat{z}_{2}+ y_4}{\\hat{z}_{2}+ y_4+y_2+ y_3}\n$$\natau kita bisa mengembalikan ke notasi $x$ seperti berikut\n\n$$\n\\hat{\\theta}^{(1)}= \\frac{\\hat{x}_{1}+ x_5}{\\hat{x}_{2}+ x_5+x_3+ x_4}\n$$\n\n\nTahap 3 dan 4 bisa kita terapkan langsung menggunakan R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexpectation <- function(theta){\n  100*( ( (1/4)*theta ) / ( (1/2) + (1/4)*theta) )\n}\n\nmaximization <- function(z2){\n  (z2 + y4) / (z2 + y2 + y3 + y4)\n}\nz2=0\ny2<- 12\ny3<- 18\ny4<- 29\n\nniter <- 100\ntheta0 <- 2\nsave_iter <- data.frame(\"iter\"=0,\"theta\"=theta0,\"z2\"=z2)\nfor (i in 1:niter){\n  x2 <- expectation(theta0)\n  theta <- maximization(x2)\n  criteria <- abs(theta-theta0)\n  theta0 <- theta\n  save_iter <- rbind(save_iter,c(i,theta0,x2))\n  if (criteria<10^-7){\n    break\n  }\n}\n\nsave_iter\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   iter     theta       z2\n1     0 2.0000000  0.00000\n2     1 0.7247706 50.00000\n3     2 0.6495300 26.59933\n4     3 0.6407827 24.51491\n5     4 0.6397040 24.26488\n6     5 0.6395701 24.23393\n7     6 0.6395534 24.23008\n8     7 0.6395513 24.22961\n9     8 0.6395511 24.22955\n10    9 0.6395511 24.22954\n```\n:::\n:::\n\njadi, untuk mendapatkan $x_{1}$ dan $x_{2}$ bisa menggunakan formula\n\n\n$$\nx_{1}=\\hat{z}_{1}= 100\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\ndan \n\n\n$$\nx_{1}=\\hat{z}_{2} = 100\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\nBerdasarkan formula tersebut diperoleh nilai estimasi untuk $x_{2}=24.23$, sedangkan $x_{1}$ tidak memiliki nilai estimasi tertentu karena tidak mempengaruhi nilai estimasi parameter $\\hat{\\theta}$. Sementara itu, nilai estimasi $\\hat{\\theta}=0.639$\n\n### Ilustrasi 2 \n\nSuatu percobaan memiliki suatu model linear sebagai berikut\n\n$$\ny_{ij} = \\mu + \\alpha_{i} + \\beta_{j} +\\epsilon_{ij}\n$$\nDari percobaan tersebut dihasilkan data sebagai berikut\n\n<table cellspacing=\"0\" border=\"0\">\n\t<colgroup span=\"5\" width=\"64\"></colgroup>\n\t<tr>\n\t\t<td style=\"border-bottom: 1px solid #000000\" height=\"19\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t</tr>\n\t<tr>\n\t\t<td rowspan=2 height=\"39\" align=\"center\" valign=middle><font color=\"#000000\">Tip</font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" colspan=4 align=\"center\" valign=bottom><font color=\"#000000\">Coupon</font></td>\n\t\t</tr>\n\t<tr>\n\t\t<td align=\"right\" valign=bottom sdval=\"1\" sdnum=\"1033;\"><font color=\"#000000\">1</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"2\" sdnum=\"1033;\"><font color=\"#000000\">2</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"3\" sdnum=\"1033;\"><font color=\"#000000\">3</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"4\" sdnum=\"1033;\"><font color=\"#000000\">4</font></td>\n\t</tr>\n\t<tr>\n\t\t<td style=\"border-top: 1px solid #000000\" height=\"19\" align=\"right\" valign=bottom sdval=\"1\" sdnum=\"1033;\"><font color=\"#000000\">1</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"9.3\" sdnum=\"1033;\"><font color=\"#000000\">9.3</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"9.4\" sdnum=\"1033;\"><font color=\"#000000\">9.4</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"9.6\" sdnum=\"1033;\"><font color=\"#000000\">9.6</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"10\" sdnum=\"1033;\"><font color=\"#000000\">10</font></td>\n\t</tr>\n\t<tr>\n\t\t<td height=\"19\" align=\"right\" valign=bottom sdval=\"2\" sdnum=\"1033;\"><font color=\"#000000\">2</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.4\" sdnum=\"1033;\"><font color=\"#000000\">9.4</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.3\" sdnum=\"1033;\"><font color=\"#000000\">9.3</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.8\" sdnum=\"1033;\"><font color=\"#000000\">9.8</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.9\" sdnum=\"1033;\"><font color=\"#000000\">9.9</font></td>\n\t</tr>\n\t<tr>\n\t\t<td height=\"19\" align=\"right\" valign=bottom sdval=\"3\" sdnum=\"1033;\"><font color=\"#000000\">3</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.2\" sdnum=\"1033;\"><font color=\"#000000\"></font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.4\" sdnum=\"1033;\"><font color=\"#000000\">9.4</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.5\" sdnum=\"1033;\"><font color=\"#000000\">9.5</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.7\" sdnum=\"1033;\"><font color=\"#000000\">9.7</font></td>\n\t</tr>\n\t<tr>\n\t\t<td height=\"19\" align=\"right\" valign=bottom sdval=\"4\" sdnum=\"1033;\"><font color=\"#000000\">4</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.7\" sdnum=\"1033;\"><font color=\"#000000\">9.7</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.6\" sdnum=\"1033;\"><font color=\"#000000\">9.6</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"10\" sdnum=\"1033;\"><font color=\"#000000\">10</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"10.2\" sdnum=\"1033;\"><font color=\"#000000\"></font></td>\n\t</tr>\n\t<tr>\n\t\t<td style=\"border-top: 1px solid #000000\" height=\"19\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t</tr>\n</table>\n\nData hasil percobaan tersebut mengandung dua missing data. Jika diketahui bahwa estimasi parameter dari model linear percobaan adalah sebagai berikut\n\n$$\n\\hat{\\mu} = \\bar{y} \n$$\n$$\n\\hat{\\alpha} = \\bar{y}_{i.}-\\bar{y}=\\frac{\\Sigma_{j=1}^{b} y_{ij}}{b}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\n$$\n\\hat{\\beta} = \\bar{y}_{.j}-\\bar{y}=\\frac{\\Sigma_{i=1}^{a} y_{ij}}{a}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\nuntuk $n=a+b$, maka hitung nilai estimasi dari dua missing data yang hilang tersebut dengan Algoritme EM menggunakan R!\n\n### Pembahasan Ilustrasi 2\n\nData pada soal tersebut kita rubah ke dalam format `long` seperti berikut:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n   Tip Coupon Response\n1    1      1      9.3\n2    2      1      9.4\n3    3      1       NA\n4    4      1      9.7\n5    1      2      9.4\n6    2      2      9.3\n7    3      2      9.4\n8    4      2      9.6\n9    1      3      9.6\n10   2      3      9.8\n11   3      3      9.5\n12   4      3     10.0\n13   1      4     10.0\n14   2      4      9.9\n15   3      4      9.7\n16   4      4       NA\n```\n:::\n:::\n\npackage yang dipakai untuk menjawab soal ini adalah \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\nKemudian kita input data dalam format long tersebut ke dalam R\n\n::: {.cell}\n\n```{.r .cell-code}\ndta <- read.table(header = TRUE,\n           text =\"Tip\tCoupon\tResponse\n1\t1\t9.3\n2\t1\t9.4\n3\t1\tNA\n4\t1\t9.7\n1\t2\t9.4\n2\t2\t9.3\n3\t2\t9.4\n4\t2\t9.6\n1\t3\t9.6\n2\t3\t9.8\n3\t3\t9.5\n4\t3\t10\n1\t4\t10\n2\t4\t9.9\n3\t4\t9.7\n4\t4\tNA\n\" )\nglimpse(dta)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 16\nColumns: 3\n$ Tip      <int> 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4\n$ Coupon   <int> 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4\n$ Response <dbl> 9.3, 9.4, NA, 9.7, 9.4, 9.3, 9.4, 9.6, 9.6, 9.8, 9.5, 10.0, 1…\n```\n:::\n:::\n\n\nSelanjutnya kita akan terapkan Algoritme EM\n\n\n1. Tahap-E\n\nKita akan estimasi dua missing data tersebut dengan menggunakan nilai estimasi parameter dan juga persamaan model linear\n\n\n$$\n\\hat{\\mu} = \\bar{y} \n$$\n$$\n\\hat{\\alpha} = \\bar{y}_{i.}-\\bar{y}=\\frac{\\Sigma_{j=1}^{b} y_{ij}}{b}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\n$$\n\\hat{\\beta} = \\bar{y}_{.j}-\\bar{y}=\\frac{\\Sigma_{i=1}^{a} y_{ij}}{a}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\n$$\ny_{\\text{miss}} = \\hat{\\mu} + \\hat{\\alpha_{i}} + \\hat{\\beta_{j}}\n$$\n\n$\\epsilon_{ij}$ tidak kita masukan karena merupakan galat, sehingga tidak dibutuhkan untuk estimasi nilai missing data.\n\nSebelum kita menghitung nilai estimasi bagi tiap-tiap parameter, kita buat dulu tambahan satu kolom untuk mengidentifikasi ada amatan hilang atau tidak\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndta <- dta %>%  mutate(is_miss = ifelse(is.na(Response),\"miss\",\"not\")\n                       )\nglimpse(dta)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 16\nColumns: 4\n$ Tip      <int> 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4\n$ Coupon   <int> 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4\n$ Response <dbl> 9.3, 9.4, NA, 9.7, 9.4, 9.3, 9.4, 9.6, 9.6, 9.8, 9.5, 10.0, 1…\n$ is_miss  <chr> \"not\", \"not\", \"miss\", \"not\", \"not\", \"not\", \"not\", \"not\", \"not…\n```\n:::\n:::\n\n\nSelanjutnya kita hitung estimasi dua nilai estimasi masing-masing parameter\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu_hat0 = dta %>% \n  #na.rm=TRUE berarti kita menghitung mean\n  # dengan mengabaikan missing data\n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull()\nmu_hat0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9.614286\n```\n:::\n\n```{.r .cell-code}\nalpha_hat0 <- dta %>% \n  group_by(Tip) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nalpha_hat0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.03928571 -0.01428571 -0.08095238  0.15238095\n```\n:::\n\n```{.r .cell-code}\nbeta_hat0 <- dta %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nbeta_hat0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.1476190 -0.1892857  0.1107143  0.2523810\n```\n:::\n:::\n\n\nselanjutnya kita masukan hasil estimasi parameter kita ke tabel `dta`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndta_calc <- dta %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\ndta_calc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 16 × 7\n     Tip Coupon Response is_miss mu_hat alpha_hat beta_hat\n   <int>  <int>    <dbl> <chr>    <dbl>     <dbl>    <dbl>\n 1     1      1      9.3 not       9.61   -0.0393   -0.148\n 2     2      1      9.4 not       9.61   -0.0143   -0.148\n 3     3      1     NA   miss      9.61   -0.0810   -0.148\n 4     4      1      9.7 not       9.61    0.152    -0.148\n 5     1      2      9.4 not       9.61   -0.0393   -0.189\n 6     2      2      9.3 not       9.61   -0.0143   -0.189\n 7     3      2      9.4 not       9.61   -0.0810   -0.189\n 8     4      2      9.6 not       9.61    0.152    -0.189\n 9     1      3      9.6 not       9.61   -0.0393    0.111\n10     2      3      9.8 not       9.61   -0.0143    0.111\n11     3      3      9.5 not       9.61   -0.0810    0.111\n12     4      3     10   not       9.61    0.152     0.111\n13     1      4     10   not       9.61   -0.0393    0.252\n14     2      4      9.9 not       9.61   -0.0143    0.252\n15     3      4      9.7 not       9.61   -0.0810    0.252\n16     4      4     NA   miss      9.61    0.152     0.252\n```\n:::\n:::\n\n\n\nkemudian kita hitung nilai estimasi untuk dua missing data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nymiss <- dta_calc %>% \n  filter(is_miss==\"miss\") %>%\n  mutate( ymiss = mu_hat+alpha_hat+beta_hat) %>% \n  pull(ymiss)\nymiss\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  9.385714 10.019048\n```\n:::\n:::\n\n\n\n\n2. Tahap-M\n\nPada tahap ini kita akan menghitung nilai estimasi paramaeter berdasarkan hasil yang diperoleh pada tahap 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# input nilai estimasi missing data\ndta_calc <- dta_calc %>% \n  mutate(Response = ifelse(is_miss==\"miss\",\n                           ymiss,\n                           Response)\n         )\ndta_calc %>% filter(is_miss==\"miss\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 7\n    Tip Coupon Response is_miss mu_hat alpha_hat beta_hat\n  <int>  <int>    <dbl> <chr>    <dbl>     <dbl>    <dbl>\n1     3      1     9.39 miss      9.61   -0.0810   -0.148\n2     4      4    10.0  miss      9.61    0.152     0.252\n```\n:::\n:::\n\n\nSelanjutnya kita hitung estimasi dua nilai estimasi masing-masing parameter\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu_hat0 = dta_calc %>% \n  #na.rm=TRUE berarti kita menghitung mean\n  # dengan mengabaikan missing data\n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull()\nmu_hat0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9.625298\n```\n:::\n\n```{.r .cell-code}\nalpha_hat <- dta_calc %>% \n  group_by(Tip) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nalpha_hat0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.03928571 -0.01428571 -0.08095238  0.15238095\n```\n:::\n\n```{.r .cell-code}\nbeta_hat0<- dta_calc %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nbeta_hat0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.17886905 -0.20029762  0.09970238  0.27946429\n```\n:::\n:::\n\n\nselanjutnya kita masukan hasil estimasi parameter kita ke tabel `dta`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndta_calc <- dta_calc %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\ndta_calc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 16 × 7\n     Tip Coupon Response is_miss mu_hat alpha_hat beta_hat\n   <int>  <int>    <dbl> <chr>    <dbl>     <dbl>    <dbl>\n 1     1      1     9.3  not       9.63   -0.0393  -0.179 \n 2     2      1     9.4  not       9.63   -0.0143  -0.179 \n 3     3      1     9.39 miss      9.63   -0.0810  -0.179 \n 4     4      1     9.7  not       9.63    0.152   -0.179 \n 5     1      2     9.4  not       9.63   -0.0393  -0.200 \n 6     2      2     9.3  not       9.63   -0.0143  -0.200 \n 7     3      2     9.4  not       9.63   -0.0810  -0.200 \n 8     4      2     9.6  not       9.63    0.152   -0.200 \n 9     1      3     9.6  not       9.63   -0.0393   0.0997\n10     2      3     9.8  not       9.63   -0.0143   0.0997\n11     3      3     9.5  not       9.63   -0.0810   0.0997\n12     4      3    10    not       9.63    0.152    0.0997\n13     1      4    10    not       9.63   -0.0393   0.279 \n14     2      4     9.9  not       9.63   -0.0143   0.279 \n15     3      4     9.7  not       9.63   -0.0810   0.279 \n16     4      4    10.0  miss      9.63    0.152    0.279 \n```\n:::\n:::\n\n3. Tahap 3 dan 4 akan kita buat dalam iterasi di R dengan memanfaatkan coding diatas\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## input data ke R\ndta <- read.table(header = TRUE,\n           text =\"Tip\tCoupon\tResponse\n1\t1\t9.3\n2\t1\t9.4\n3\t1\tNA\n4\t1\t9.7\n1\t2\t9.4\n2\t2\t9.3\n3\t2\t9.4\n4\t2\t9.6\n1\t3\t9.6\n2\t3\t9.8\n3\t3\t9.5\n4\t3\t10\n1\t4\t10\n2\t4\t9.9\n3\t4\t9.7\n4\t4\tNA\n\" )\nglimpse(dta)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 16\nColumns: 3\n$ Tip      <int> 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4\n$ Coupon   <int> 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4\n$ Response <dbl> 9.3, 9.4, NA, 9.7, 9.4, 9.3, 9.4, 9.6, 9.6, 9.8, 9.5, 10.0, 1…\n```\n:::\n:::\n\n\nBerikutnya kita mulai EM-algorithm. \n\nPada bagian ini akan diilustrasikan missing data akan diganti dengan nilai awal dibandingkan dengan nilai estimasi yang didapatkan dari parameter seperti ilustrasi sebelumnya.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# menambahkan kolom dengan informasi missing data\ndta <- dta %>%  mutate(is_miss = ifelse(is.na(Response),\"miss\",\"not\")\n                       )\n\n## Menghitung estimasi parameter dengan nilai awal 2 \n\n dta <- dta %>% \n  mutate( Response = ifelse(is_miss==\"miss\",\n                            2,\n                            Response)\n  )\n\nmu_hat0 = dta %>% \n  summarise(mean(Response)) %>% \n  pull()\n\nalpha_hat0 <- dta %>% \n  group_by(Tip) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\n\nbeta_hat0 <- dta %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\n\n# memasukan hasil estimasi paramater ke dalam data.frame\ndta_calc <- dta %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\n\n# nilai estimasi missing data\nymiss_rec <- dta_calc %>% \n  filter(is_miss==\"miss\")\n\n# y_missing nilai awal 2\nymiss =c(2,2)\nres_table <- data.frame(iter=0,\n           name_ymiss=c(\"y31\",\"y44\"),\n           ymiss=ymiss,\n           mu_hat = ymiss_rec %>% pull(mu_hat),\n           alpha_hat = ymiss_rec %>% pull(alpha_hat),\n           beta_hat = ymiss_rec %>% pull(beta_hat)\n           )\ntol <- 1e-7\n\nfor (i in 1:100){\n  \n\n# input nilai estimasi missing data\ndta_calc <- dta_calc %>% \n  mutate(Response = ifelse(is_miss==\"miss\",\n                           ymiss,\n                           Response)\n         )\n\nmu_hat0 = dta_calc %>% \n  summarise(mean(Response)) %>% \n  pull()\n\n\nalpha_hat0 <- dta_calc %>% \n  group_by(Tip) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\n\nbeta_hat0 <- dta_calc %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\ndta_calc <- dta_calc %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\n\n\n# nilai estimasi missing data\nymiss_rec <- dta_calc %>% \n  filter(is_miss==\"miss\") %>%\n  mutate( ymiss = mu_hat+alpha_hat+beta_hat)\n  \nymiss_old <- ymiss\nymiss <- ymiss_rec %>%  pull(ymiss)\n\nres_table <- rbind(res_table,data.frame(iter=i,\n           name_ymiss=c(\"y31\",\"y44\"),\n           ymiss=ymiss,\n           mu_hat = ymiss_rec %>% pull(mu_hat),\n           alpha_hat = ymiss_rec %>% pull(alpha_hat),\n           beta_hat = ymiss_rec %>% pull(beta_hat)\n           ))\nif(all(abs(ymiss_old-ymiss)<=tol)){\n  break\n}\n\n}\n```\n:::\n\n\nHasil akhir yang diperoleh\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   iter name_ymiss     ymiss   mu_hat   alpha_hat   beta_hat\n1     0        y31  2.000000 8.662500 -1.01250000 -1.0625000\n2     0        y44  2.000000 8.662500 -0.83750000 -0.7625000\n3     1        y31  6.587500 8.662500 -1.01250000 -1.0625000\n4     1        y44  7.062500 8.662500 -0.83750000 -0.7625000\n5     2        y31  8.278125 9.265625 -0.46875000 -0.5187500\n6     2        y44  8.990625 9.265625 -0.17500000 -0.1000000\n7     3        y31  8.897266 9.491797 -0.27226563 -0.3222656\n8     3        y44  9.728516 9.491797  0.08085937  0.1558594\n9     4        y31  9.122021 9.576611 -0.20229492 -0.2522949\n10    4        y44 10.012646 9.576611  0.18051758  0.2555176\n11    5        y31  9.202594 9.608417 -0.17791138 -0.2279114\n12    5        y44 10.122906 9.608417  0.21974487  0.2947449\n13    6        y31  9.230953 9.620344 -0.16969528 -0.2196953\n14    6        y44 10.166109 9.620344  0.23538284  0.3103828\n15    7        y31  9.240660 9.624816 -0.16707811 -0.2170781\n16    7        y44 10.183238 9.624816  0.24171095  0.3167109\n17    8        y31  9.243836 9.626494 -0.16632861 -0.2163286\n18    8        y44 10.190126 9.626494  0.24431592  0.3193159\n19    9        y31  9.244796 9.627123 -0.16616351 -0.2161635\n20    9        y44 10.192940 9.627123  0.24540875  0.3204088\n21   10        y31  9.245039 9.627358 -0.16615958 -0.2161596\n22   10        y44 10.194112 9.627358  0.24587655  0.3208765\n23   11        y31  9.245073 9.627447 -0.16618710 -0.2161871\n24   11        y44 10.194609 9.627447  0.24608096  0.3210810\n25   12        y31  9.245056 9.627480 -0.16621192 -0.2162119\n26   12        y44 10.194824 9.627480  0.24617212  0.3211721\n27   13        y31  9.245036 9.627493 -0.16622847 -0.2162285\n28   13        y44 10.194920 9.627493  0.24621355  0.3212135\n29   14        y31  9.245021 9.627497 -0.16623830 -0.2162383\n30   14        y44 10.194963 9.627497  0.24623271  0.3212327\n31   15        y31  9.245011 9.627499 -0.16624380 -0.2162438\n32   15        y44 10.194982 9.627499  0.24624170  0.3212417\n33   16        y31  9.245006 9.627500 -0.16624677 -0.2162468\n34   16        y44 10.194992 9.627500  0.24624598  0.3212460\n35   17        y31  9.245003 9.627500 -0.16624834 -0.2162483\n36   17        y44 10.194996 9.627500  0.24624804  0.3212480\n37   18        y31  9.245002 9.627500 -0.16624915 -0.2162491\n38   18        y44 10.194998 9.627500  0.24624904  0.3212490\n39   19        y31  9.245001 9.627500 -0.16624957 -0.2162496\n40   19        y44 10.194999 9.627500  0.24624953  0.3212495\n41   20        y31  9.245000 9.627500 -0.16624978 -0.2162498\n42   20        y44 10.195000 9.627500  0.24624977  0.3212498\n43   21        y31  9.245000 9.627500 -0.16624989 -0.2162499\n44   21        y44 10.195000 9.627500  0.24624988  0.3212499\n45   22        y31  9.245000 9.627500 -0.16624994 -0.2162499\n46   22        y44 10.195000 9.627500  0.24624994  0.3212499\n47   23        y31  9.245000 9.627500 -0.16624997 -0.2162500\n48   23        y44 10.195000 9.627500  0.24624997  0.3212500\n```\n:::\n:::\n\n\n\n\n## Referensi\n\nHogg, Robert V., Joseph W. McKean, and Allen T,Craig.2013. Introduction to Mathematical Statistics. 7th ed. Boston: Pearson.\n\nhttps://www.statisticshowto.com/em-algorithm-expectation-maximization/",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}