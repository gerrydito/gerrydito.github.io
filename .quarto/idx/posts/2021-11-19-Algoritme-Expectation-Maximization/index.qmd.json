{"title":"Algoritme Expectation-Maximization (EM) menggunakan R","markdown":{"yaml":{"title":"Algoritme Expectation-Maximization (EM) menggunakan R","date":"11-19-2021","author":"Gerry Alfa Dito","categories":["R Programming","Computational Statistics"],"draft":false,"image":"post-image.jpg"},"headingText":"Algoritme EM","containsRefs":false,"markdown":"\n\n\n\n**Algoritme EM** adalah cara untuk menghitung estimasi parameter model menggunakan Metode **MLE (Maksimum Likelihood Estimation)** ketika data yang kita **tidak lengkap**, memiliki **missing data**, atau memiliki variabel laten (latent variable) yang tak teramati. Secara singkat EM bisa diartikan sebagai metode untuk iteratif yang bisa mendekati Likelihood function. **Metode MLE** memiliki hanya bisa mengestimasi parameter dengan baik jika **data** yang kita miliki **tidak lengkap**. Algoritme EM bekerja dengan memilih **nilai acak** untuk titik data yang tidak lengkap, dan menggunakan **nilai acak** tersebut untuk mengestimasi data yang tidak lengkap. \n\n\nMisalkan $X=(X_{1},X_{2},\\ldots,X_{n_{1}})$ merupakan sampel yang teramati (observed) dan $Z=(Z_{1},Z_{2},\\ldots,Z_{n_{2}})$ merupakan sampel yang tak teramati (unobserved) dengan $n=n_{1}+n_{2}$. Asumsikan bahwa $X_{i}$ i.i.d dengan pdf $f(x|\\theta)$ dan $Z_{j}$ serta $X_{i}$ saling lepas. Misalkan $g(x|\\theta)$ merupakan **joint pdf** dari $X$ dan $h(x,z|\\theta)$ merupakan **joint pdf** antara **observed** dan **unobserved**. **Conditional pdf** dari **unobserved** adalah\n\n$$\nf(z|\\theta,x)=\\frac{h(x,z|\\theta)}{g(x|\\theta)}\n$$\nFungsi observed likelihood didefinisikan $L(\\theta|x)=g(x|\\theta)$ dan fungsi complete likelihood didefinisikan $L^{c}(\\theta|x,z)=h(x,z|\\theta)$\n\n\nTahap-tahap dalam Algoritme EM dapat ditulis sebagai berikut\n\n1. Isi data yang tak lengkap tersebut dengan suatu nilai estimasi yang didapatkan dari nilai Ekspetasi fungsi log-Likelihood\n\n$$\nQ(\\theta|\\hat{\\theta}^{(m)})=\\text{E}_{\\hat{\\theta}^{(m)}}\\left[\\log{L^{c}(\\theta|x,z)}|\\hat{\\theta}^{(m)},x\\right]=\\int_{-\\infty}^{\\infty}\\log{[h(x,z|\\theta)]}f(z|\\hat{\\theta}^{(m)},x)\n$$\n\nTahap 1 ini sering disebut dengan **Tahap Expectation** atau **Tahap-E**\n\n\n2. Dari tahap 1 kita sudah memperoleh **data lengkap**, selanjutnya **estimasi parameter** menggunakan data lengkap tersebut. Estimasi parameter dilakukan dengan menerapkan metode MLE pada fungsi $Q(\\theta|\\hat{\\theta}^{(m)})$ sebagai berikut:\n\n$$\n\\hat{\\theta}^{(m+1)}= \\arg \\max{Q(\\theta|\\hat{\\theta}^{(m)})}\n$$\nTahap 2 ini sering disebut dengan **Tahap Maximization** atau **Tahap-M**\n\n3. Gunakan parameter hasil estimasi pada tahap 2 untuk mendapatkan nilai estimasi yang baru\n\n4. Gunakan nilai estimasi yang baru pada tahap 3 untuk mendapatkan estimasi parameter yang baru\n\nLakukan langkah 3 dan 4 sampai konvergen\n\n\n## Penerapan Algoritme EM\n\nBerikut adalah beberapa penerapan EM-Algorithm\n\n1. Missing Data Problems\n2. Grouped Data Problems\n3. Truncated and Censored Data Problems\n4. Latent Variable Estimation\n5. Mixtures Model\n\n\n\n\n### Ilustrasi 1\n\nRao (1973) melakukan pembagian secara acak 197 hewan menjadi 4 kategori berdasarkan phenotypes sedemikian sehingga:\n\n$$\n\\boldsymbol{y} = (y_{1}, y_{2}, y_{3}, y_{4})^{T} = (100, 12, 18, 29)^{T}\n$$\n\ndengan peluang setiap kategori\n\n$$\n\\left(p_{1}={\\frac{1}{2}+\\frac{\\theta}{4},p_{2}=\\frac{1-\\theta}{4},p_{3}=\\frac{1-\\theta}{4},p_{4}=\\frac{\\theta}{4}}\\right)\n$$\n\nsehingga $\\boldsymbol{y}\\sim \\text{Multinomial}(p_{1},p_{2},p_{3},p_{4})$. Fungsi kepekatan peluang (fkp) atau probability density function (pdf) dari $\\boldsymbol{y}$ adalah\n\n$$\ng(\\boldsymbol{y}|\\theta) = \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\n\n\nJika peneliti menambahkan satu kategori lagi dengan memecah kategori pertama menjadi 2 kategori sedemikian sehingga\n\n$$\\boldsymbol{x} = (x_{1},x_{2},x_{3},x_{4},x_{5})^{T}$$\n\ndimana $x_{1}+x_{2}=y_{1},x_{3}=y_{2},x_{4}=y_{3},x_{5}=y_{4}$dengan peluang setiap kategori menjadi\n\n\n$$\n\\left(\\frac{1}{2},\\frac{\\theta}{4},\\frac{1-\\theta}{4},\\frac{1-\\theta}{4},\\frac{\\theta}{4}\\right)\n$$\n\n\nsehingga $\\boldsymbol{x}\\sim \\text{Multinomial}(p_{1},p_{2},p_{3},p_{4},p_{5})$. Fungsi kepekatan peluang (fkp) atau probability density function (pdf) dari $\\boldsymbol{x}$ adalah\n\n\n$$\nf(\\boldsymbol{x}|\\theta) = \\frac{x_{1}+x_{2}+x_{3}+x_{4}+x_{5}}{x_{1}! x_{2}! x_{3}! x_{4}! x_{5}!} \\left(\\frac{1}{2}\\right) ^{x_{1}} \\left(\\frac{\\theta}{4} \\right) ^{x_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{x_{3}} \\left(\\frac{1-\\theta}{4}\\right)^{x_{4}} \\left(\\frac{\\theta}{4}\\right)^{x_{5}}\n$$\n\nJika diketahui fungsi log-likelihood bagi $y$ adalah\n\n$$\n\\log{L(\\theta|y)} = c+y_{1} \\log{(2+\\theta)} + (y_{2} + y_{3}) \\log{(1-\\theta)} + y_{4} \\log{\\theta}\n$$\ndan fungsi fungsi log-likelihood bagi $x$ adalah\n\n\n$$\n\\log{L(\\theta|x)} = c+x_{1}\\log{\\left(\\frac{1}{2}\\right)}+(x_2+ x_5)\\log{\\theta} + (x_3+x_4) \\log{ (1-\\theta)} \n$$\n\na. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $y$\nb. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $x$\nc. Hitunglah estimasi $x_1$,$x_2$ dan $\\hat{\\theta}$ menggunakan Algoritme EM dengan toleransi $10^{-7}$!\n\n### Pembahasan Ilustrasi 1\n\n\na. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $y$\n\nFungsi Likelihood bagi $y$ \n\n$$\nL(\\theta|\\boldsymbol{y}) = g(\\boldsymbol{y}|\\theta)\n$$\n$$\nL(\\theta|\\boldsymbol{y}) = \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\nfungsi log-likelihood bagi $y$\n\n$$\n\\log{L(\\theta|y)} = \\log{\\left( \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!}\\ \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}} \\right)}\n$$\n\n$$\n\\log{L(\\theta|y)} = \\log{\\left( \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\right)} + \\log{\\left(\\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right)  ^{y_{1}}\\right)} + \\log{\\left(\\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\right)} + \\log{\\left(\\left(\\frac{1-\\theta}{4}\\right)^{y_{3}}\\right)} + \\log{\\left(\\left(\\frac{\\theta}{4}\\right)^{y_{4}}\\right)} \n$$\nkita misalkan bagian yang tidak ada unsur $\\theta$ sebagai $c$ atau konstanta\n\n\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right)} + y_{2} \\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{3}\\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{4}\\log{\\left(\\frac{\\theta}{4}\\right)} \n$$\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(\\frac{2+\\theta}{4} \\right)} + y_{2} \\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{3}\\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{4}\\log{\\left(\\frac{\\theta}{4}\\right)} \n$$\n\n\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(2+\\theta \\right)}- y_{1} \\log{\\left(4 \\right)} + y_{2} \\log{\\left(1-\\theta\\right)}-y_{2} \\log{\\left({4}\\right)} + y_{3}\\log{\\left({1-\\theta}\\right)}-y_{3}\\log{\\left({4}\\right)} + y_{4}\\log{\\left(\\theta\\right)} - y_{4}\\log{\\left(4\\right)} \n$$\n\nkemudian kita gabungan semua bagian yang tidak mengandung $\\theta$ menjadi $c$ atau konstanta\n\n\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(2+\\theta \\right)} + y_{2} \\log{\\left(1-\\theta\\right)} + y_{3}\\log{\\left({1-\\theta}\\right)} + y_{4}\\log{\\left(\\theta\\right)}  \n$$\n\nb. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $x$\n\nSilahkan kerjakan sebagai latihan\n\n\nc. Hitunglah estimasi $x_1$,$x_2$ dan $\\hat{\\theta}$ menggunakan Algoritme EM dengan toleransi $10^{-7}$!\n\n1. Isi data yang tak lengkap tersebut dengan suatu nilai estimasi yang didapatkan dari nilai Ekspetasi fungsi log-Likelihood\n\n$$\nQ(\\theta|\\hat{\\theta}^{(m)})=\\text{E}_{\\hat{\\theta}^{(m)}}\\left[\\log{L^{c}(\\theta|x,z)}|\\hat{\\theta}^{(m)},x\\right]\n$$\n\nTahap 1 ini sering disebut dengan **Tahap Expectation** atau **Tahap-E**\n\n\nPada tahap 1 ini hal pertama yang kita lakukan adalah menentukan fungsi **complete log-likelihood** $\\log{L^{c}(\\theta|x,z)}$ yang bisa kita ambil dari fungsi **log-likelihood** bagi $x$\n\n$$\n\\log{L(\\theta|x)} = c+x_{1}\\log{\\left(\\frac{1}{2}\\right)}+(x_2+ x_5)\\log{\\theta} + (x_3+x_4) \\log{ (1-\\theta)} \n$$\nkarena di dalam fungsi ini terdapat data unobserved $x_{1}$ dan $x_{2}$ serta data observed $x_{3},x_{4},x_{5}$ sehingga jika digabungkan akan menjadi fungsi **complete log-likelihood**\n\nUntuk mempermudah perhitungan kita misalkan $z_{1}=x_{1}$ dan $z_{1}=x_{2}$, yang mana $x_{1}$ dan $x_{2}$ merupakan data unobserved. Sehingga $\\boldsymbol{z}=(z_{1},z_{2})$. Kemudian, kita tahu bahwa $x_{3}=y_{2},x_{4}=y_{3},x_{5}=y_{4}$ sehingga kita rubah simbol $x$ menjadi $y$. Jadi fungsi **complete log-likelihood** adalah sebagai berikut\n\n$$\n\\log{L^{c}(\\theta|y,z}) = c+z_{1}\\log{\\left(\\frac{1}{2}\\right)}+(z_2+ y_4)\\log{\\theta} + (y_2+y_3) \\log{ (1-\\theta)}  \n$$\n\nkemudian kita hitung fungsi $Q(\\theta|\\hat{\\theta}^{(0)}$\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})=\\text{E}_{\\hat{\\theta}^{(0)}}[\\log{L^{c}(\\theta|y,z)}|\\hat{\\theta}^{(0)},y] \n$$\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= \\text{E}_{\\hat{\\theta}^{(0)}}\\left[c+z_{1}\\log{\\left(\\frac{1}{2}\\right)}+(z_2+ y_4)\\log{\\theta} + (y_2+y_3) \\log{ (1-\\theta)} |\\hat{\\theta}^{(0)},y \\right]\n$$\n\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= \\text{E}_{\\hat{\\theta}^{(0)}}\\left[c|\\hat{\\theta}^{(0)},y\\right]+\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\log{\\left(\\frac{1}{2}\\right)}|\\hat{\\theta}^{(0)},y\\right]+\\text{E}_{\\hat{\\theta}^{(0)}}\\left[(z_2+ y_4)|\\hat{\\theta}^{(0)},y\\right]\\log{\\theta} + \\text{E}_{\\hat{\\theta}^{(0)}}\\left[(y_2+ y_3)|\\hat{\\theta}^{(0)},y\\right] \\log{(1-\\theta)} \n$$\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= 0+\\log{\\left(\\frac{1}{2}\\right)}\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}|\\hat{\\theta}^{(0)},y \\right]+\\left(\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= \\log{\\left(\\frac{1}{2}\\right)}\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y]+\\left(\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n\nUntuk memperoleh nilai dari $\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y]$ dan $\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]$, kita perlu tahu terlebih dahulu tentang distribusi dari $\\boldsymbol{z}=(z_{1},z_{2})$. Karena $\\boldsymbol{z}=(z_{1},z_{2})$ merupakan data unobserved maka kita bisa mendapatkan pdf dari $\\boldsymbol{z}$ dengan\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{h(\\boldsymbol{y},\\boldsymbol{z}|\\theta)}{g(\\boldsymbol{y}|\\theta)}\n$$\ndengan \n$$\nh(\\boldsymbol{x},\\boldsymbol{z}|\\theta)=L^{c}(\\theta|\\boldsymbol{y},\\boldsymbol{z} )=  \\frac{z_{1}+z_{2}+y_{2}+y_{3}+y_{4}}{z_{1}! z_{2}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\nyang merupakan fungsi **complete likelihood**. Kemudian\n\n$$\ng(\\boldsymbol{y}|\\theta)=L(\\theta|\\boldsymbol{y})=\\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\nyang merupakan fungsi **observed likelihood**. Jadi diperoleh\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{(z_{1}+z_{2}+y_{2}+y_{3}+y_{4})!}{z_{1}! z_{2}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}{\\frac{(y_{1}+y_{2}+y_{3}+y_{4})!}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}\n$$\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{n!}{z_{1}! z_{2}! y_{2}! y_{3}! y_{4}!}  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}{\\frac{n!}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}\n$$\n\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{1}{z_{1}! z_{2}! }  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} }{\\frac{1}{y_{1}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}}}\n$$\n\nkarena $z_{1}+z_{2}=y_{1}$ maka\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{y_{1}!}{z_{1}! z_{2}! }  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} }{ \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{z_{1}+z_{2}}}\n$$\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{y_{1}!}{z_{1}! z_{2}! }  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} }{ \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right)^{z_{1}}  \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{z_{2}}}\n$$\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! z_{2}! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\n\n\n\n\nBerdasarkan hasil diatas, kita dapat memperoleh pdf dari $z_{1}$ dan $z_{2}$ dengan memanfaatkan $z_{1}+z_{2}=y_{1}$. \n\n\nUntuk pdf $z_{1}$\n\n\n$$\nf(z_{1}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! (y_{1}-z_{1})! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(\\frac{\\frac{\\theta}{4}+\\frac{1}{2}-\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{y_{1}-z_{1}}\n$$\n$$\nf(z_{1}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! (y_{1}-z_{1})! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(\\frac{\\frac{1}{2}+\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }   -\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{y_{1}-z_{1}}\n$$\n$$\nf(z_{1}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! (y_{1}-z_{1})! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(1   -\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{y_{1}-z_{1}}\n$$\n\nsehingga $z_{1}$ memiliki distribusi $\\text{Binomial}\\left(y_{1},\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)$\n\n\nKemudian untuk pdf $z_{2}$\n\n$$\nf(z_2|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{(y_{1}-z_{2})! z_{2}! } \\left(\\frac{  \\frac{1}{2}+\\frac{\\theta}{4}-\\frac{\\theta}{4}  }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{y_{1}-z_{2}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\n$$\nf(z_2|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{(y_{1}-z_{2})! z_{2}! } \\left(\\frac{  \\frac{1}{2}+\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} } - \\frac{\\frac{\\theta}{4}  }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{y_{1}-z_{2}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\n\n$$\nf(z_2|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{(y_{1}-z_{2})! z_{2}! } \\left(1 - \\frac{\\frac{\\theta}{4}  }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{y_{1}-z_{2}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\nsehingga $z_{2}$ memiliki distribusi $\\text{Binomial}\\left(y_{1},\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)$\n\n\n**Ingat** bahwa jika $X \\sim \\text{Binomial}(n,p)$ maka nilai ekspetasinya adalah\n\n$$\n\\text{E}(X)=np\n$$\n\nsehingga \n\n$$\n\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y] = y_{1}\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\ndan\n\n\n$$\n\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]=y_{1}\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\nuntuk memudahkan penulisan kita misalkan \n\n$$\n\\hat{z}_{1} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y] = y_{1}\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\nkarena $y_{1}=100$ maka\n\n$$\n\\hat{z}_{1} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y] = 100\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\ndan \n\n$$\n\\hat{z}_{2} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]=y_{1}\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\nkarena $y_{1}=100$ maka\n\n$$\n\\hat{z}_{2} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]=100\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\njadi\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})=\\log{\\left(\\frac{1}{2}\\right)}\\hat{z}_{1}+\\left(\\hat{z}_{2}+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n\n\n2. Dari langkah 1 kita sudah memperoleh **data lengkap**, selanjutnya **estimasi parameter** menggunakan data lengkap tersebut. Estimasi parameter dilakukan dengan menerapkan metode MLE pada fungsi $Q(\\theta|\\hat{\\theta}^{(m)})$ sebagai berikut:\n\n$$\n\\hat{\\theta}^{(m+1)}= \\arg \\max{Q(\\theta|\\hat{\\theta}^{(m)})}\n$$\nTahap 2 ini sering disebut dengan **Tahap Maximization** atau **Tahap-M**\n\nBerdasarkan Tahap 1 diperoleh\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})=\\log{\\left(\\frac{1}{2}\\right)}\\hat{z}_{1}+\\left(\\hat{z}_{2}+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n\nKemudian, kita akan memperoleh $\\hat{\\theta}^{(m)}$ dengan memaksimumkan $Q(\\theta|\\hat{\\theta}^{(0)})$ \n\n$$\n\\hat{\\theta}^{(1)}= \\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})}\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{d\\space Q(\\theta|\\hat{\\theta}^{(0)})}{d\\space \\theta}=0\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{d\\space \\log{\\left(\\frac{1}{2}\\right)}\\hat{z}_{1}+\\left(\\hat{z}_{2}+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} }{d\\space \\theta}=0\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff 0 +\\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{{\\theta}} + \\frac{(y_2+ y_3)}{(1-\\theta)} =0\n$$\n\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{{\\theta}} - \\frac{(y_2+ y_3)}{(1-\\theta)} =0\n$$\n\n\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{{\\theta}} = \\frac{(y_2+ y_3)}{(1-\\theta)}\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{{\\theta}}{\\left(\\hat{z}_{2}+ y_4\\right)} = \\frac{(1-\\theta)}{(y_2+ y_3)}\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{{\\theta}}{(1-\\theta)} = \\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{(y_2+ y_3)}\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3)= \\left(\\hat{z}_{2}+ y_4\\right)(1-\\theta)\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3)= \\left(\\hat{z}_{2}+ y_4\\right)-\\theta\\left(\\hat{z}_{2}+ y_4\\right)\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3)+\\theta\\left(\\hat{z}_{2}+ y_4\\right)= \\left(\\hat{z}_{2}+ y_4\\right)\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3+\\hat{z}_{2}+ y_4)= \\left(\\hat{z}_{2}+ y_4\\right)\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\hat{\\theta}= \\frac{\\hat{z}_{2}+ y_4}{y_2+ y_3+\\hat{z}_{2}+ y_4}\n$$\njadi\n\n$$\n\\hat{\\theta}^{(1)}= \\frac{\\hat{z}_{2}+ y_4}{\\hat{z}_{2}+ y_4+y_2+ y_3}\n$$\natau kita bisa mengembalikan ke notasi $x$ seperti berikut\n\n$$\n\\hat{\\theta}^{(1)}= \\frac{\\hat{x}_{1}+ x_5}{\\hat{x}_{2}+ x_5+x_3+ x_4}\n$$\n\n\nTahap 3 dan 4 bisa kita terapkan langsung menggunakan R\n\n```{r}\nexpectation <- function(theta){\n  100*( ( (1/4)*theta ) / ( (1/2) + (1/4)*theta) )\n}\n\nmaximization <- function(z2){\n  (z2 + y4) / (z2 + y2 + y3 + y4)\n}\nz2=0\ny2<- 12\ny3<- 18\ny4<- 29\n\nniter <- 100\ntheta0 <- 2\nsave_iter <- data.frame(\"iter\"=0,\"theta\"=theta0,\"z2\"=z2)\nfor (i in 1:niter){\n  x2 <- expectation(theta0)\n  theta <- maximization(x2)\n  criteria <- abs(theta-theta0)\n  theta0 <- theta\n  save_iter <- rbind(save_iter,c(i,theta0,x2))\n  if (criteria<10^-7){\n    break\n  }\n}\n\nsave_iter\n```\njadi, untuk mendapatkan $x_{1}$ dan $x_{2}$ bisa menggunakan formula\n\n\n$$\nx_{1}=\\hat{z}_{1}= 100\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\ndan \n\n\n$$\nx_{1}=\\hat{z}_{2} = 100\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\nBerdasarkan formula tersebut diperoleh nilai estimasi untuk $x_{2}=24.23$, sedangkan $x_{1}$ tidak memiliki nilai estimasi tertentu karena tidak mempengaruhi nilai estimasi parameter $\\hat{\\theta}$. Sementara itu, nilai estimasi $\\hat{\\theta}=0.639$\n\n### Ilustrasi 2 \n\nSuatu percobaan memiliki suatu model linear sebagai berikut\n\n$$\ny_{ij} = \\mu + \\alpha_{i} + \\beta_{j} +\\epsilon_{ij}\n$$\nDari percobaan tersebut dihasilkan data sebagai berikut\n\n<table cellspacing=\"0\" border=\"0\">\n\t<colgroup span=\"5\" width=\"64\"></colgroup>\n\t<tr>\n\t\t<td style=\"border-bottom: 1px solid #000000\" height=\"19\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t</tr>\n\t<tr>\n\t\t<td rowspan=2 height=\"39\" align=\"center\" valign=middle><font color=\"#000000\">Tip</font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" colspan=4 align=\"center\" valign=bottom><font color=\"#000000\">Coupon</font></td>\n\t\t</tr>\n\t<tr>\n\t\t<td align=\"right\" valign=bottom sdval=\"1\" sdnum=\"1033;\"><font color=\"#000000\">1</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"2\" sdnum=\"1033;\"><font color=\"#000000\">2</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"3\" sdnum=\"1033;\"><font color=\"#000000\">3</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"4\" sdnum=\"1033;\"><font color=\"#000000\">4</font></td>\n\t</tr>\n\t<tr>\n\t\t<td style=\"border-top: 1px solid #000000\" height=\"19\" align=\"right\" valign=bottom sdval=\"1\" sdnum=\"1033;\"><font color=\"#000000\">1</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"9.3\" sdnum=\"1033;\"><font color=\"#000000\">9.3</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"9.4\" sdnum=\"1033;\"><font color=\"#000000\">9.4</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"9.6\" sdnum=\"1033;\"><font color=\"#000000\">9.6</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"10\" sdnum=\"1033;\"><font color=\"#000000\">10</font></td>\n\t</tr>\n\t<tr>\n\t\t<td height=\"19\" align=\"right\" valign=bottom sdval=\"2\" sdnum=\"1033;\"><font color=\"#000000\">2</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.4\" sdnum=\"1033;\"><font color=\"#000000\">9.4</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.3\" sdnum=\"1033;\"><font color=\"#000000\">9.3</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.8\" sdnum=\"1033;\"><font color=\"#000000\">9.8</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.9\" sdnum=\"1033;\"><font color=\"#000000\">9.9</font></td>\n\t</tr>\n\t<tr>\n\t\t<td height=\"19\" align=\"right\" valign=bottom sdval=\"3\" sdnum=\"1033;\"><font color=\"#000000\">3</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.2\" sdnum=\"1033;\"><font color=\"#000000\"></font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.4\" sdnum=\"1033;\"><font color=\"#000000\">9.4</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.5\" sdnum=\"1033;\"><font color=\"#000000\">9.5</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.7\" sdnum=\"1033;\"><font color=\"#000000\">9.7</font></td>\n\t</tr>\n\t<tr>\n\t\t<td height=\"19\" align=\"right\" valign=bottom sdval=\"4\" sdnum=\"1033;\"><font color=\"#000000\">4</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.7\" sdnum=\"1033;\"><font color=\"#000000\">9.7</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.6\" sdnum=\"1033;\"><font color=\"#000000\">9.6</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"10\" sdnum=\"1033;\"><font color=\"#000000\">10</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"10.2\" sdnum=\"1033;\"><font color=\"#000000\"></font></td>\n\t</tr>\n\t<tr>\n\t\t<td style=\"border-top: 1px solid #000000\" height=\"19\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t</tr>\n</table>\n\nData hasil percobaan tersebut mengandung dua missing data. Jika diketahui bahwa estimasi parameter dari model linear percobaan adalah sebagai berikut\n\n$$\n\\hat{\\mu} = \\bar{y} \n$$\n$$\n\\hat{\\alpha} = \\bar{y}_{i.}-\\bar{y}=\\frac{\\Sigma_{j=1}^{b} y_{ij}}{b}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\n$$\n\\hat{\\beta} = \\bar{y}_{.j}-\\bar{y}=\\frac{\\Sigma_{i=1}^{a} y_{ij}}{a}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\nuntuk $n=a+b$, maka hitung nilai estimasi dari dua missing data yang hilang tersebut dengan Algoritme EM menggunakan R!\n\n### Pembahasan Ilustrasi 2\n\nData pada soal tersebut kita rubah ke dalam format `long` seperti berikut:\n\n```{r echo=FALSE}\nread.table(header = TRUE,\n           text =\"Tip\tCoupon\tResponse\n1\t1\t9.3\n2\t1\t9.4\n3\t1\tNA\n4\t1\t9.7\n1\t2\t9.4\n2\t2\t9.3\n3\t2\t9.4\n4\t2\t9.6\n1\t3\t9.6\n2\t3\t9.8\n3\t3\t9.5\n4\t3\t10\n1\t4\t10\n2\t4\t9.9\n3\t4\t9.7\n4\t4\tNA\n\" )\n```\npackage yang dipakai untuk menjawab soal ini adalah \n\n```{r message=FALSE}\nlibrary(tidyverse)\n```\n\nKemudian kita input data dalam format long tersebut ke dalam R\n```{r}\ndta <- read.table(header = TRUE,\n           text =\"Tip\tCoupon\tResponse\n1\t1\t9.3\n2\t1\t9.4\n3\t1\tNA\n4\t1\t9.7\n1\t2\t9.4\n2\t2\t9.3\n3\t2\t9.4\n4\t2\t9.6\n1\t3\t9.6\n2\t3\t9.8\n3\t3\t9.5\n4\t3\t10\n1\t4\t10\n2\t4\t9.9\n3\t4\t9.7\n4\t4\tNA\n\" )\nglimpse(dta)\n```\n\nSelanjutnya kita akan terapkan Algoritme EM\n\n\n1. Tahap-E\n\nKita akan estimasi dua missing data tersebut dengan menggunakan nilai estimasi parameter dan juga persamaan model linear\n\n\n$$\n\\hat{\\mu} = \\bar{y} \n$$\n$$\n\\hat{\\alpha} = \\bar{y}_{i.}-\\bar{y}=\\frac{\\Sigma_{j=1}^{b} y_{ij}}{b}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\n$$\n\\hat{\\beta} = \\bar{y}_{.j}-\\bar{y}=\\frac{\\Sigma_{i=1}^{a} y_{ij}}{a}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\n$$\ny_{\\text{miss}} = \\hat{\\mu} + \\hat{\\alpha_{i}} + \\hat{\\beta_{j}}\n$$\n\n$\\epsilon_{ij}$ tidak kita masukan karena merupakan galat, sehingga tidak dibutuhkan untuk estimasi nilai missing data.\n\nSebelum kita menghitung nilai estimasi bagi tiap-tiap parameter, kita buat dulu tambahan satu kolom untuk mengidentifikasi ada amatan hilang atau tidak\n\n\n```{r}\ndta <- dta %>%  mutate(is_miss = ifelse(is.na(Response),\"miss\",\"not\")\n                       )\nglimpse(dta)\n```\n\nSelanjutnya kita hitung estimasi dua nilai estimasi masing-masing parameter\n\n\n```{r}\nmu_hat0 = dta %>% \n  #na.rm=TRUE berarti kita menghitung mean\n  # dengan mengabaikan missing data\n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull()\nmu_hat0\n\nalpha_hat0 <- dta %>% \n  group_by(Tip) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nalpha_hat0\n\nbeta_hat0 <- dta %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nbeta_hat0\n```\n\nselanjutnya kita masukan hasil estimasi parameter kita ke tabel `dta`\n\n```{r}\ndta_calc <- dta %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\ndta_calc\n```\n\n\nkemudian kita hitung nilai estimasi untuk dua missing data\n\n```{r}\nymiss <- dta_calc %>% \n  filter(is_miss==\"miss\") %>%\n  mutate( ymiss = mu_hat+alpha_hat+beta_hat) %>% \n  pull(ymiss)\nymiss\n```\n\n\n\n2. Tahap-M\n\nPada tahap ini kita akan menghitung nilai estimasi paramaeter berdasarkan hasil yang diperoleh pada tahap 1\n\n```{r}\n# input nilai estimasi missing data\ndta_calc <- dta_calc %>% \n  mutate(Response = ifelse(is_miss==\"miss\",\n                           ymiss,\n                           Response)\n         )\ndta_calc %>% filter(is_miss==\"miss\")\n```\n\nSelanjutnya kita hitung estimasi dua nilai estimasi masing-masing parameter\n\n\n```{r}\nmu_hat0 = dta_calc %>% \n  #na.rm=TRUE berarti kita menghitung mean\n  # dengan mengabaikan missing data\n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull()\nmu_hat0\n\nalpha_hat <- dta_calc %>% \n  group_by(Tip) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nalpha_hat0\n\nbeta_hat0<- dta_calc %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nbeta_hat0\n```\n\nselanjutnya kita masukan hasil estimasi parameter kita ke tabel `dta`\n\n```{r}\ndta_calc <- dta_calc %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\ndta_calc\n```\n3. Tahap 3 dan 4 akan kita buat dalam iterasi di R dengan memanfaatkan coding diatas\n\n\n```{r}\n## input data ke R\ndta <- read.table(header = TRUE,\n           text =\"Tip\tCoupon\tResponse\n1\t1\t9.3\n2\t1\t9.4\n3\t1\tNA\n4\t1\t9.7\n1\t2\t9.4\n2\t2\t9.3\n3\t2\t9.4\n4\t2\t9.6\n1\t3\t9.6\n2\t3\t9.8\n3\t3\t9.5\n4\t3\t10\n1\t4\t10\n2\t4\t9.9\n3\t4\t9.7\n4\t4\tNA\n\" )\nglimpse(dta)\n```\n\nBerikutnya kita mulai EM-algorithm. \n\nPada bagian ini akan diilustrasikan missing data akan diganti dengan nilai awal dibandingkan dengan nilai estimasi yang didapatkan dari parameter seperti ilustrasi sebelumnya.\n\n```{r}\n# menambahkan kolom dengan informasi missing data\ndta <- dta %>%  mutate(is_miss = ifelse(is.na(Response),\"miss\",\"not\")\n                       )\n\n## Menghitung estimasi parameter dengan nilai awal 2 \n\n dta <- dta %>% \n  mutate( Response = ifelse(is_miss==\"miss\",\n                            2,\n                            Response)\n  )\n\nmu_hat0 = dta %>% \n  summarise(mean(Response)) %>% \n  pull()\n\nalpha_hat0 <- dta %>% \n  group_by(Tip) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\n\nbeta_hat0 <- dta %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\n\n# memasukan hasil estimasi paramater ke dalam data.frame\ndta_calc <- dta %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\n\n# nilai estimasi missing data\nymiss_rec <- dta_calc %>% \n  filter(is_miss==\"miss\")\n\n# y_missing nilai awal 2\nymiss =c(2,2)\nres_table <- data.frame(iter=0,\n           name_ymiss=c(\"y31\",\"y44\"),\n           ymiss=ymiss,\n           mu_hat = ymiss_rec %>% pull(mu_hat),\n           alpha_hat = ymiss_rec %>% pull(alpha_hat),\n           beta_hat = ymiss_rec %>% pull(beta_hat)\n           )\ntol <- 1e-7\n\nfor (i in 1:100){\n  \n\n# input nilai estimasi missing data\ndta_calc <- dta_calc %>% \n  mutate(Response = ifelse(is_miss==\"miss\",\n                           ymiss,\n                           Response)\n         )\n\nmu_hat0 = dta_calc %>% \n  summarise(mean(Response)) %>% \n  pull()\n\n\nalpha_hat0 <- dta_calc %>% \n  group_by(Tip) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\n\nbeta_hat0 <- dta_calc %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\ndta_calc <- dta_calc %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\n\n\n# nilai estimasi missing data\nymiss_rec <- dta_calc %>% \n  filter(is_miss==\"miss\") %>%\n  mutate( ymiss = mu_hat+alpha_hat+beta_hat)\n  \nymiss_old <- ymiss\nymiss <- ymiss_rec %>%  pull(ymiss)\n\nres_table <- rbind(res_table,data.frame(iter=i,\n           name_ymiss=c(\"y31\",\"y44\"),\n           ymiss=ymiss,\n           mu_hat = ymiss_rec %>% pull(mu_hat),\n           alpha_hat = ymiss_rec %>% pull(alpha_hat),\n           beta_hat = ymiss_rec %>% pull(beta_hat)\n           ))\nif(all(abs(ymiss_old-ymiss)<=tol)){\n  break\n}\n\n}\n```\n\nHasil akhir yang diperoleh\n\n```{r}\nres_table\n```\n\n\n\n## Referensi\n\nHogg, Robert V., Joseph W. McKean, and Allen T,Craig.2013. Introduction to Mathematical Statistics. 7th ed. Boston: Pearson.\n\nhttps://www.statisticshowto.com/em-algorithm-expectation-maximization/","srcMarkdownNoYaml":"\n\n\n## Algoritme EM\n\n**Algoritme EM** adalah cara untuk menghitung estimasi parameter model menggunakan Metode **MLE (Maksimum Likelihood Estimation)** ketika data yang kita **tidak lengkap**, memiliki **missing data**, atau memiliki variabel laten (latent variable) yang tak teramati. Secara singkat EM bisa diartikan sebagai metode untuk iteratif yang bisa mendekati Likelihood function. **Metode MLE** memiliki hanya bisa mengestimasi parameter dengan baik jika **data** yang kita miliki **tidak lengkap**. Algoritme EM bekerja dengan memilih **nilai acak** untuk titik data yang tidak lengkap, dan menggunakan **nilai acak** tersebut untuk mengestimasi data yang tidak lengkap. \n\n\nMisalkan $X=(X_{1},X_{2},\\ldots,X_{n_{1}})$ merupakan sampel yang teramati (observed) dan $Z=(Z_{1},Z_{2},\\ldots,Z_{n_{2}})$ merupakan sampel yang tak teramati (unobserved) dengan $n=n_{1}+n_{2}$. Asumsikan bahwa $X_{i}$ i.i.d dengan pdf $f(x|\\theta)$ dan $Z_{j}$ serta $X_{i}$ saling lepas. Misalkan $g(x|\\theta)$ merupakan **joint pdf** dari $X$ dan $h(x,z|\\theta)$ merupakan **joint pdf** antara **observed** dan **unobserved**. **Conditional pdf** dari **unobserved** adalah\n\n$$\nf(z|\\theta,x)=\\frac{h(x,z|\\theta)}{g(x|\\theta)}\n$$\nFungsi observed likelihood didefinisikan $L(\\theta|x)=g(x|\\theta)$ dan fungsi complete likelihood didefinisikan $L^{c}(\\theta|x,z)=h(x,z|\\theta)$\n\n\nTahap-tahap dalam Algoritme EM dapat ditulis sebagai berikut\n\n1. Isi data yang tak lengkap tersebut dengan suatu nilai estimasi yang didapatkan dari nilai Ekspetasi fungsi log-Likelihood\n\n$$\nQ(\\theta|\\hat{\\theta}^{(m)})=\\text{E}_{\\hat{\\theta}^{(m)}}\\left[\\log{L^{c}(\\theta|x,z)}|\\hat{\\theta}^{(m)},x\\right]=\\int_{-\\infty}^{\\infty}\\log{[h(x,z|\\theta)]}f(z|\\hat{\\theta}^{(m)},x)\n$$\n\nTahap 1 ini sering disebut dengan **Tahap Expectation** atau **Tahap-E**\n\n\n2. Dari tahap 1 kita sudah memperoleh **data lengkap**, selanjutnya **estimasi parameter** menggunakan data lengkap tersebut. Estimasi parameter dilakukan dengan menerapkan metode MLE pada fungsi $Q(\\theta|\\hat{\\theta}^{(m)})$ sebagai berikut:\n\n$$\n\\hat{\\theta}^{(m+1)}= \\arg \\max{Q(\\theta|\\hat{\\theta}^{(m)})}\n$$\nTahap 2 ini sering disebut dengan **Tahap Maximization** atau **Tahap-M**\n\n3. Gunakan parameter hasil estimasi pada tahap 2 untuk mendapatkan nilai estimasi yang baru\n\n4. Gunakan nilai estimasi yang baru pada tahap 3 untuk mendapatkan estimasi parameter yang baru\n\nLakukan langkah 3 dan 4 sampai konvergen\n\n\n## Penerapan Algoritme EM\n\nBerikut adalah beberapa penerapan EM-Algorithm\n\n1. Missing Data Problems\n2. Grouped Data Problems\n3. Truncated and Censored Data Problems\n4. Latent Variable Estimation\n5. Mixtures Model\n\n\n\n\n### Ilustrasi 1\n\nRao (1973) melakukan pembagian secara acak 197 hewan menjadi 4 kategori berdasarkan phenotypes sedemikian sehingga:\n\n$$\n\\boldsymbol{y} = (y_{1}, y_{2}, y_{3}, y_{4})^{T} = (100, 12, 18, 29)^{T}\n$$\n\ndengan peluang setiap kategori\n\n$$\n\\left(p_{1}={\\frac{1}{2}+\\frac{\\theta}{4},p_{2}=\\frac{1-\\theta}{4},p_{3}=\\frac{1-\\theta}{4},p_{4}=\\frac{\\theta}{4}}\\right)\n$$\n\nsehingga $\\boldsymbol{y}\\sim \\text{Multinomial}(p_{1},p_{2},p_{3},p_{4})$. Fungsi kepekatan peluang (fkp) atau probability density function (pdf) dari $\\boldsymbol{y}$ adalah\n\n$$\ng(\\boldsymbol{y}|\\theta) = \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\n\n\nJika peneliti menambahkan satu kategori lagi dengan memecah kategori pertama menjadi 2 kategori sedemikian sehingga\n\n$$\\boldsymbol{x} = (x_{1},x_{2},x_{3},x_{4},x_{5})^{T}$$\n\ndimana $x_{1}+x_{2}=y_{1},x_{3}=y_{2},x_{4}=y_{3},x_{5}=y_{4}$dengan peluang setiap kategori menjadi\n\n\n$$\n\\left(\\frac{1}{2},\\frac{\\theta}{4},\\frac{1-\\theta}{4},\\frac{1-\\theta}{4},\\frac{\\theta}{4}\\right)\n$$\n\n\nsehingga $\\boldsymbol{x}\\sim \\text{Multinomial}(p_{1},p_{2},p_{3},p_{4},p_{5})$. Fungsi kepekatan peluang (fkp) atau probability density function (pdf) dari $\\boldsymbol{x}$ adalah\n\n\n$$\nf(\\boldsymbol{x}|\\theta) = \\frac{x_{1}+x_{2}+x_{3}+x_{4}+x_{5}}{x_{1}! x_{2}! x_{3}! x_{4}! x_{5}!} \\left(\\frac{1}{2}\\right) ^{x_{1}} \\left(\\frac{\\theta}{4} \\right) ^{x_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{x_{3}} \\left(\\frac{1-\\theta}{4}\\right)^{x_{4}} \\left(\\frac{\\theta}{4}\\right)^{x_{5}}\n$$\n\nJika diketahui fungsi log-likelihood bagi $y$ adalah\n\n$$\n\\log{L(\\theta|y)} = c+y_{1} \\log{(2+\\theta)} + (y_{2} + y_{3}) \\log{(1-\\theta)} + y_{4} \\log{\\theta}\n$$\ndan fungsi fungsi log-likelihood bagi $x$ adalah\n\n\n$$\n\\log{L(\\theta|x)} = c+x_{1}\\log{\\left(\\frac{1}{2}\\right)}+(x_2+ x_5)\\log{\\theta} + (x_3+x_4) \\log{ (1-\\theta)} \n$$\n\na. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $y$\nb. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $x$\nc. Hitunglah estimasi $x_1$,$x_2$ dan $\\hat{\\theta}$ menggunakan Algoritme EM dengan toleransi $10^{-7}$!\n\n### Pembahasan Ilustrasi 1\n\n\na. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $y$\n\nFungsi Likelihood bagi $y$ \n\n$$\nL(\\theta|\\boldsymbol{y}) = g(\\boldsymbol{y}|\\theta)\n$$\n$$\nL(\\theta|\\boldsymbol{y}) = \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\nfungsi log-likelihood bagi $y$\n\n$$\n\\log{L(\\theta|y)} = \\log{\\left( \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!}\\ \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}} \\right)}\n$$\n\n$$\n\\log{L(\\theta|y)} = \\log{\\left( \\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\right)} + \\log{\\left(\\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right)  ^{y_{1}}\\right)} + \\log{\\left(\\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\right)} + \\log{\\left(\\left(\\frac{1-\\theta}{4}\\right)^{y_{3}}\\right)} + \\log{\\left(\\left(\\frac{\\theta}{4}\\right)^{y_{4}}\\right)} \n$$\nkita misalkan bagian yang tidak ada unsur $\\theta$ sebagai $c$ atau konstanta\n\n\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right)} + y_{2} \\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{3}\\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{4}\\log{\\left(\\frac{\\theta}{4}\\right)} \n$$\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(\\frac{2+\\theta}{4} \\right)} + y_{2} \\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{3}\\log{\\left(\\frac{1-\\theta}{4}\\right)} + y_{4}\\log{\\left(\\frac{\\theta}{4}\\right)} \n$$\n\n\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(2+\\theta \\right)}- y_{1} \\log{\\left(4 \\right)} + y_{2} \\log{\\left(1-\\theta\\right)}-y_{2} \\log{\\left({4}\\right)} + y_{3}\\log{\\left({1-\\theta}\\right)}-y_{3}\\log{\\left({4}\\right)} + y_{4}\\log{\\left(\\theta\\right)} - y_{4}\\log{\\left(4\\right)} \n$$\n\nkemudian kita gabungan semua bagian yang tidak mengandung $\\theta$ menjadi $c$ atau konstanta\n\n\n$$\n\\log{L(\\theta|y)} = c + y_{1} \\log{\\left(2+\\theta \\right)} + y_{2} \\log{\\left(1-\\theta\\right)} + y_{3}\\log{\\left({1-\\theta}\\right)} + y_{4}\\log{\\left(\\theta\\right)}  \n$$\n\nb. Tunjukkan cara memperoleh fungsi-loglikelihood bagi $x$\n\nSilahkan kerjakan sebagai latihan\n\n\nc. Hitunglah estimasi $x_1$,$x_2$ dan $\\hat{\\theta}$ menggunakan Algoritme EM dengan toleransi $10^{-7}$!\n\n1. Isi data yang tak lengkap tersebut dengan suatu nilai estimasi yang didapatkan dari nilai Ekspetasi fungsi log-Likelihood\n\n$$\nQ(\\theta|\\hat{\\theta}^{(m)})=\\text{E}_{\\hat{\\theta}^{(m)}}\\left[\\log{L^{c}(\\theta|x,z)}|\\hat{\\theta}^{(m)},x\\right]\n$$\n\nTahap 1 ini sering disebut dengan **Tahap Expectation** atau **Tahap-E**\n\n\nPada tahap 1 ini hal pertama yang kita lakukan adalah menentukan fungsi **complete log-likelihood** $\\log{L^{c}(\\theta|x,z)}$ yang bisa kita ambil dari fungsi **log-likelihood** bagi $x$\n\n$$\n\\log{L(\\theta|x)} = c+x_{1}\\log{\\left(\\frac{1}{2}\\right)}+(x_2+ x_5)\\log{\\theta} + (x_3+x_4) \\log{ (1-\\theta)} \n$$\nkarena di dalam fungsi ini terdapat data unobserved $x_{1}$ dan $x_{2}$ serta data observed $x_{3},x_{4},x_{5}$ sehingga jika digabungkan akan menjadi fungsi **complete log-likelihood**\n\nUntuk mempermudah perhitungan kita misalkan $z_{1}=x_{1}$ dan $z_{1}=x_{2}$, yang mana $x_{1}$ dan $x_{2}$ merupakan data unobserved. Sehingga $\\boldsymbol{z}=(z_{1},z_{2})$. Kemudian, kita tahu bahwa $x_{3}=y_{2},x_{4}=y_{3},x_{5}=y_{4}$ sehingga kita rubah simbol $x$ menjadi $y$. Jadi fungsi **complete log-likelihood** adalah sebagai berikut\n\n$$\n\\log{L^{c}(\\theta|y,z}) = c+z_{1}\\log{\\left(\\frac{1}{2}\\right)}+(z_2+ y_4)\\log{\\theta} + (y_2+y_3) \\log{ (1-\\theta)}  \n$$\n\nkemudian kita hitung fungsi $Q(\\theta|\\hat{\\theta}^{(0)}$\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})=\\text{E}_{\\hat{\\theta}^{(0)}}[\\log{L^{c}(\\theta|y,z)}|\\hat{\\theta}^{(0)},y] \n$$\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= \\text{E}_{\\hat{\\theta}^{(0)}}\\left[c+z_{1}\\log{\\left(\\frac{1}{2}\\right)}+(z_2+ y_4)\\log{\\theta} + (y_2+y_3) \\log{ (1-\\theta)} |\\hat{\\theta}^{(0)},y \\right]\n$$\n\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= \\text{E}_{\\hat{\\theta}^{(0)}}\\left[c|\\hat{\\theta}^{(0)},y\\right]+\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\log{\\left(\\frac{1}{2}\\right)}|\\hat{\\theta}^{(0)},y\\right]+\\text{E}_{\\hat{\\theta}^{(0)}}\\left[(z_2+ y_4)|\\hat{\\theta}^{(0)},y\\right]\\log{\\theta} + \\text{E}_{\\hat{\\theta}^{(0)}}\\left[(y_2+ y_3)|\\hat{\\theta}^{(0)},y\\right] \\log{(1-\\theta)} \n$$\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= 0+\\log{\\left(\\frac{1}{2}\\right)}\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}|\\hat{\\theta}^{(0)},y \\right]+\\left(\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})= \\log{\\left(\\frac{1}{2}\\right)}\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y]+\\left(\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n\nUntuk memperoleh nilai dari $\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y]$ dan $\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]$, kita perlu tahu terlebih dahulu tentang distribusi dari $\\boldsymbol{z}=(z_{1},z_{2})$. Karena $\\boldsymbol{z}=(z_{1},z_{2})$ merupakan data unobserved maka kita bisa mendapatkan pdf dari $\\boldsymbol{z}$ dengan\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{h(\\boldsymbol{y},\\boldsymbol{z}|\\theta)}{g(\\boldsymbol{y}|\\theta)}\n$$\ndengan \n$$\nh(\\boldsymbol{x},\\boldsymbol{z}|\\theta)=L^{c}(\\theta|\\boldsymbol{y},\\boldsymbol{z} )=  \\frac{z_{1}+z_{2}+y_{2}+y_{3}+y_{4}}{z_{1}! z_{2}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\nyang merupakan fungsi **complete likelihood**. Kemudian\n\n$$\ng(\\boldsymbol{y}|\\theta)=L(\\theta|\\boldsymbol{y})=\\frac{y_{1}+y_{2}+y_{3}+y_{4}}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}\n$$\nyang merupakan fungsi **observed likelihood**. Jadi diperoleh\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{(z_{1}+z_{2}+y_{2}+y_{3}+y_{4})!}{z_{1}! z_{2}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}{\\frac{(y_{1}+y_{2}+y_{3}+y_{4})!}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}\n$$\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{n!}{z_{1}! z_{2}! y_{2}! y_{3}! y_{4}!}  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}{\\frac{n!}{y_{1}! y_{2}! y_{3}! y_{4}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{2}} \\left(\\frac{1-\\theta}{4}\\right)^{y_{3}} \\left(\\frac{\\theta}{4}\\right)^{y_{4}}}\n$$\n\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{1}{z_{1}! z_{2}! }  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} }{\\frac{1}{y_{1}!} \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{y_{1}}}\n$$\n\nkarena $z_{1}+z_{2}=y_{1}$ maka\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{y_{1}!}{z_{1}! z_{2}! }  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} }{ \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{z_{1}+z_{2}}}\n$$\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{\\frac{y_{1}!}{z_{1}! z_{2}! }  \\left(\\frac{1}{2}\\right) ^{z_{1}} \\left(\\frac{\\theta}{4} \\right) ^{z_{2}} }{ \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right)^{z_{1}}  \\left(\\frac{1}{2}+\\frac{\\theta}{4} \\right) ^{z_{2}}}\n$$\n\n$$\nf(\\boldsymbol{z}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! z_{2}! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\n\n\n\n\nBerdasarkan hasil diatas, kita dapat memperoleh pdf dari $z_{1}$ dan $z_{2}$ dengan memanfaatkan $z_{1}+z_{2}=y_{1}$. \n\n\nUntuk pdf $z_{1}$\n\n\n$$\nf(z_{1}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! (y_{1}-z_{1})! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(\\frac{\\frac{\\theta}{4}+\\frac{1}{2}-\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{y_{1}-z_{1}}\n$$\n$$\nf(z_{1}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! (y_{1}-z_{1})! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(\\frac{\\frac{1}{2}+\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }   -\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{y_{1}-z_{1}}\n$$\n$$\nf(z_{1}|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{z_{1}! (y_{1}-z_{1})! } \\left(\\frac{  \\frac{1}{2} }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{z_{1}} \\left(1   -\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{y_{1}-z_{1}}\n$$\n\nsehingga $z_{1}$ memiliki distribusi $\\text{Binomial}\\left(y_{1},\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)$\n\n\nKemudian untuk pdf $z_{2}$\n\n$$\nf(z_2|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{(y_{1}-z_{2})! z_{2}! } \\left(\\frac{  \\frac{1}{2}+\\frac{\\theta}{4}-\\frac{\\theta}{4}  }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{y_{1}-z_{2}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\n$$\nf(z_2|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{(y_{1}-z_{2})! z_{2}! } \\left(\\frac{  \\frac{1}{2}+\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} } - \\frac{\\frac{\\theta}{4}  }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{y_{1}-z_{2}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\n\n$$\nf(z_2|\\theta,\\boldsymbol{y})=\\frac{y_{1}!}{(y_{1}-z_{2})! z_{2}! } \\left(1 - \\frac{\\frac{\\theta}{4}  }{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)^{y_{1}-z_{2}} \\left(\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right) ^{z_{2}}\n$$\nsehingga $z_{2}$ memiliki distribusi $\\text{Binomial}\\left(y_{1},\\frac{\\frac{\\theta}{4}}{\\frac{1}{2}+\\frac{\\theta}{4} }\\right)$\n\n\n**Ingat** bahwa jika $X \\sim \\text{Binomial}(n,p)$ maka nilai ekspetasinya adalah\n\n$$\n\\text{E}(X)=np\n$$\n\nsehingga \n\n$$\n\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y] = y_{1}\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\ndan\n\n\n$$\n\\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]=y_{1}\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\nuntuk memudahkan penulisan kita misalkan \n\n$$\n\\hat{z}_{1} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y] = y_{1}\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\nkarena $y_{1}=100$ maka\n\n$$\n\\hat{z}_{1} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_{1}\\right|\\hat{\\theta}^{(0)},y] = 100\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\ndan \n\n$$\n\\hat{z}_{2} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]=y_{1}\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\nkarena $y_{1}=100$ maka\n\n$$\n\\hat{z}_{2} = \\text{E}_{\\hat{\\theta}^{(0)}}\\left[z_2|\\hat{\\theta}^{(0)},y\\right]=100\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\njadi\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})=\\log{\\left(\\frac{1}{2}\\right)}\\hat{z}_{1}+\\left(\\hat{z}_{2}+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n\n\n2. Dari langkah 1 kita sudah memperoleh **data lengkap**, selanjutnya **estimasi parameter** menggunakan data lengkap tersebut. Estimasi parameter dilakukan dengan menerapkan metode MLE pada fungsi $Q(\\theta|\\hat{\\theta}^{(m)})$ sebagai berikut:\n\n$$\n\\hat{\\theta}^{(m+1)}= \\arg \\max{Q(\\theta|\\hat{\\theta}^{(m)})}\n$$\nTahap 2 ini sering disebut dengan **Tahap Maximization** atau **Tahap-M**\n\nBerdasarkan Tahap 1 diperoleh\n\n$$\nQ(\\theta|\\hat{\\theta}^{(0)})=\\log{\\left(\\frac{1}{2}\\right)}\\hat{z}_{1}+\\left(\\hat{z}_{2}+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} \n$$\n\nKemudian, kita akan memperoleh $\\hat{\\theta}^{(m)}$ dengan memaksimumkan $Q(\\theta|\\hat{\\theta}^{(0)})$ \n\n$$\n\\hat{\\theta}^{(1)}= \\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})}\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{d\\space Q(\\theta|\\hat{\\theta}^{(0)})}{d\\space \\theta}=0\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{d\\space \\log{\\left(\\frac{1}{2}\\right)}\\hat{z}_{1}+\\left(\\hat{z}_{2}+ y_4\\right)\\log{\\theta} + (y_2+ y_3) \\log{(1-\\theta)} }{d\\space \\theta}=0\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff 0 +\\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{{\\theta}} + \\frac{(y_2+ y_3)}{(1-\\theta)} =0\n$$\n\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{{\\theta}} - \\frac{(y_2+ y_3)}{(1-\\theta)} =0\n$$\n\n\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{{\\theta}} = \\frac{(y_2+ y_3)}{(1-\\theta)}\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{{\\theta}}{\\left(\\hat{z}_{2}+ y_4\\right)} = \\frac{(1-\\theta)}{(y_2+ y_3)}\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\frac{{\\theta}}{(1-\\theta)} = \\frac{\\left(\\hat{z}_{2}+ y_4\\right)}{(y_2+ y_3)}\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3)= \\left(\\hat{z}_{2}+ y_4\\right)(1-\\theta)\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3)= \\left(\\hat{z}_{2}+ y_4\\right)-\\theta\\left(\\hat{z}_{2}+ y_4\\right)\n$$\n\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3)+\\theta\\left(\\hat{z}_{2}+ y_4\\right)= \\left(\\hat{z}_{2}+ y_4\\right)\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\theta(y_2+ y_3+\\hat{z}_{2}+ y_4)= \\left(\\hat{z}_{2}+ y_4\\right)\n$$\n$$\n\\arg \\max{Q(\\theta|\\hat{\\theta}^{(0)})} \\iff \\hat{\\theta}= \\frac{\\hat{z}_{2}+ y_4}{y_2+ y_3+\\hat{z}_{2}+ y_4}\n$$\njadi\n\n$$\n\\hat{\\theta}^{(1)}= \\frac{\\hat{z}_{2}+ y_4}{\\hat{z}_{2}+ y_4+y_2+ y_3}\n$$\natau kita bisa mengembalikan ke notasi $x$ seperti berikut\n\n$$\n\\hat{\\theta}^{(1)}= \\frac{\\hat{x}_{1}+ x_5}{\\hat{x}_{2}+ x_5+x_3+ x_4}\n$$\n\n\nTahap 3 dan 4 bisa kita terapkan langsung menggunakan R\n\n```{r}\nexpectation <- function(theta){\n  100*( ( (1/4)*theta ) / ( (1/2) + (1/4)*theta) )\n}\n\nmaximization <- function(z2){\n  (z2 + y4) / (z2 + y2 + y3 + y4)\n}\nz2=0\ny2<- 12\ny3<- 18\ny4<- 29\n\nniter <- 100\ntheta0 <- 2\nsave_iter <- data.frame(\"iter\"=0,\"theta\"=theta0,\"z2\"=z2)\nfor (i in 1:niter){\n  x2 <- expectation(theta0)\n  theta <- maximization(x2)\n  criteria <- abs(theta-theta0)\n  theta0 <- theta\n  save_iter <- rbind(save_iter,c(i,theta0,x2))\n  if (criteria<10^-7){\n    break\n  }\n}\n\nsave_iter\n```\njadi, untuk mendapatkan $x_{1}$ dan $x_{2}$ bisa menggunakan formula\n\n\n$$\nx_{1}=\\hat{z}_{1}= 100\\left(\\frac{\\frac{1}{2}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\ndan \n\n\n$$\nx_{1}=\\hat{z}_{2} = 100\\left(\\frac{\\frac{\\hat{\\theta}^{(0)}}{4}}{\\frac{1}{2}+\\frac{\\hat{\\theta}^{(0)}}{4} }\\right)\n$$\n\nBerdasarkan formula tersebut diperoleh nilai estimasi untuk $x_{2}=24.23$, sedangkan $x_{1}$ tidak memiliki nilai estimasi tertentu karena tidak mempengaruhi nilai estimasi parameter $\\hat{\\theta}$. Sementara itu, nilai estimasi $\\hat{\\theta}=0.639$\n\n### Ilustrasi 2 \n\nSuatu percobaan memiliki suatu model linear sebagai berikut\n\n$$\ny_{ij} = \\mu + \\alpha_{i} + \\beta_{j} +\\epsilon_{ij}\n$$\nDari percobaan tersebut dihasilkan data sebagai berikut\n\n<table cellspacing=\"0\" border=\"0\">\n\t<colgroup span=\"5\" width=\"64\"></colgroup>\n\t<tr>\n\t\t<td style=\"border-bottom: 1px solid #000000\" height=\"19\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t</tr>\n\t<tr>\n\t\t<td rowspan=2 height=\"39\" align=\"center\" valign=middle><font color=\"#000000\">Tip</font></td>\n\t\t<td style=\"border-bottom: 1px solid #000000\" colspan=4 align=\"center\" valign=bottom><font color=\"#000000\">Coupon</font></td>\n\t\t</tr>\n\t<tr>\n\t\t<td align=\"right\" valign=bottom sdval=\"1\" sdnum=\"1033;\"><font color=\"#000000\">1</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"2\" sdnum=\"1033;\"><font color=\"#000000\">2</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"3\" sdnum=\"1033;\"><font color=\"#000000\">3</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"4\" sdnum=\"1033;\"><font color=\"#000000\">4</font></td>\n\t</tr>\n\t<tr>\n\t\t<td style=\"border-top: 1px solid #000000\" height=\"19\" align=\"right\" valign=bottom sdval=\"1\" sdnum=\"1033;\"><font color=\"#000000\">1</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"9.3\" sdnum=\"1033;\"><font color=\"#000000\">9.3</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"9.4\" sdnum=\"1033;\"><font color=\"#000000\">9.4</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"9.6\" sdnum=\"1033;\"><font color=\"#000000\">9.6</font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"right\" valign=bottom sdval=\"10\" sdnum=\"1033;\"><font color=\"#000000\">10</font></td>\n\t</tr>\n\t<tr>\n\t\t<td height=\"19\" align=\"right\" valign=bottom sdval=\"2\" sdnum=\"1033;\"><font color=\"#000000\">2</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.4\" sdnum=\"1033;\"><font color=\"#000000\">9.4</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.3\" sdnum=\"1033;\"><font color=\"#000000\">9.3</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.8\" sdnum=\"1033;\"><font color=\"#000000\">9.8</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.9\" sdnum=\"1033;\"><font color=\"#000000\">9.9</font></td>\n\t</tr>\n\t<tr>\n\t\t<td height=\"19\" align=\"right\" valign=bottom sdval=\"3\" sdnum=\"1033;\"><font color=\"#000000\">3</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.2\" sdnum=\"1033;\"><font color=\"#000000\"></font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.4\" sdnum=\"1033;\"><font color=\"#000000\">9.4</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.5\" sdnum=\"1033;\"><font color=\"#000000\">9.5</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.7\" sdnum=\"1033;\"><font color=\"#000000\">9.7</font></td>\n\t</tr>\n\t<tr>\n\t\t<td height=\"19\" align=\"right\" valign=bottom sdval=\"4\" sdnum=\"1033;\"><font color=\"#000000\">4</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.7\" sdnum=\"1033;\"><font color=\"#000000\">9.7</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"9.6\" sdnum=\"1033;\"><font color=\"#000000\">9.6</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"10\" sdnum=\"1033;\"><font color=\"#000000\">10</font></td>\n\t\t<td align=\"right\" valign=bottom sdval=\"10.2\" sdnum=\"1033;\"><font color=\"#000000\"></font></td>\n\t</tr>\n\t<tr>\n\t\t<td style=\"border-top: 1px solid #000000\" height=\"19\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t\t<td style=\"border-top: 1px solid #000000\" align=\"left\" valign=bottom><font color=\"#000000\"><br></font></td>\n\t</tr>\n</table>\n\nData hasil percobaan tersebut mengandung dua missing data. Jika diketahui bahwa estimasi parameter dari model linear percobaan adalah sebagai berikut\n\n$$\n\\hat{\\mu} = \\bar{y} \n$$\n$$\n\\hat{\\alpha} = \\bar{y}_{i.}-\\bar{y}=\\frac{\\Sigma_{j=1}^{b} y_{ij}}{b}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\n$$\n\\hat{\\beta} = \\bar{y}_{.j}-\\bar{y}=\\frac{\\Sigma_{i=1}^{a} y_{ij}}{a}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\nuntuk $n=a+b$, maka hitung nilai estimasi dari dua missing data yang hilang tersebut dengan Algoritme EM menggunakan R!\n\n### Pembahasan Ilustrasi 2\n\nData pada soal tersebut kita rubah ke dalam format `long` seperti berikut:\n\n```{r echo=FALSE}\nread.table(header = TRUE,\n           text =\"Tip\tCoupon\tResponse\n1\t1\t9.3\n2\t1\t9.4\n3\t1\tNA\n4\t1\t9.7\n1\t2\t9.4\n2\t2\t9.3\n3\t2\t9.4\n4\t2\t9.6\n1\t3\t9.6\n2\t3\t9.8\n3\t3\t9.5\n4\t3\t10\n1\t4\t10\n2\t4\t9.9\n3\t4\t9.7\n4\t4\tNA\n\" )\n```\npackage yang dipakai untuk menjawab soal ini adalah \n\n```{r message=FALSE}\nlibrary(tidyverse)\n```\n\nKemudian kita input data dalam format long tersebut ke dalam R\n```{r}\ndta <- read.table(header = TRUE,\n           text =\"Tip\tCoupon\tResponse\n1\t1\t9.3\n2\t1\t9.4\n3\t1\tNA\n4\t1\t9.7\n1\t2\t9.4\n2\t2\t9.3\n3\t2\t9.4\n4\t2\t9.6\n1\t3\t9.6\n2\t3\t9.8\n3\t3\t9.5\n4\t3\t10\n1\t4\t10\n2\t4\t9.9\n3\t4\t9.7\n4\t4\tNA\n\" )\nglimpse(dta)\n```\n\nSelanjutnya kita akan terapkan Algoritme EM\n\n\n1. Tahap-E\n\nKita akan estimasi dua missing data tersebut dengan menggunakan nilai estimasi parameter dan juga persamaan model linear\n\n\n$$\n\\hat{\\mu} = \\bar{y} \n$$\n$$\n\\hat{\\alpha} = \\bar{y}_{i.}-\\bar{y}=\\frac{\\Sigma_{j=1}^{b} y_{ij}}{b}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\n$$\n\\hat{\\beta} = \\bar{y}_{.j}-\\bar{y}=\\frac{\\Sigma_{i=1}^{a} y_{ij}}{a}-\\frac{\\Sigma_{j=1}^{n} y_{ij}}{n}\n$$\n$$\ny_{\\text{miss}} = \\hat{\\mu} + \\hat{\\alpha_{i}} + \\hat{\\beta_{j}}\n$$\n\n$\\epsilon_{ij}$ tidak kita masukan karena merupakan galat, sehingga tidak dibutuhkan untuk estimasi nilai missing data.\n\nSebelum kita menghitung nilai estimasi bagi tiap-tiap parameter, kita buat dulu tambahan satu kolom untuk mengidentifikasi ada amatan hilang atau tidak\n\n\n```{r}\ndta <- dta %>%  mutate(is_miss = ifelse(is.na(Response),\"miss\",\"not\")\n                       )\nglimpse(dta)\n```\n\nSelanjutnya kita hitung estimasi dua nilai estimasi masing-masing parameter\n\n\n```{r}\nmu_hat0 = dta %>% \n  #na.rm=TRUE berarti kita menghitung mean\n  # dengan mengabaikan missing data\n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull()\nmu_hat0\n\nalpha_hat0 <- dta %>% \n  group_by(Tip) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nalpha_hat0\n\nbeta_hat0 <- dta %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nbeta_hat0\n```\n\nselanjutnya kita masukan hasil estimasi parameter kita ke tabel `dta`\n\n```{r}\ndta_calc <- dta %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\ndta_calc\n```\n\n\nkemudian kita hitung nilai estimasi untuk dua missing data\n\n```{r}\nymiss <- dta_calc %>% \n  filter(is_miss==\"miss\") %>%\n  mutate( ymiss = mu_hat+alpha_hat+beta_hat) %>% \n  pull(ymiss)\nymiss\n```\n\n\n\n2. Tahap-M\n\nPada tahap ini kita akan menghitung nilai estimasi paramaeter berdasarkan hasil yang diperoleh pada tahap 1\n\n```{r}\n# input nilai estimasi missing data\ndta_calc <- dta_calc %>% \n  mutate(Response = ifelse(is_miss==\"miss\",\n                           ymiss,\n                           Response)\n         )\ndta_calc %>% filter(is_miss==\"miss\")\n```\n\nSelanjutnya kita hitung estimasi dua nilai estimasi masing-masing parameter\n\n\n```{r}\nmu_hat0 = dta_calc %>% \n  #na.rm=TRUE berarti kita menghitung mean\n  # dengan mengabaikan missing data\n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull()\nmu_hat0\n\nalpha_hat <- dta_calc %>% \n  group_by(Tip) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nalpha_hat0\n\nbeta_hat0<- dta_calc %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response,na.rm=TRUE)) %>% \n  pull() - mu_hat0\nbeta_hat0\n```\n\nselanjutnya kita masukan hasil estimasi parameter kita ke tabel `dta`\n\n```{r}\ndta_calc <- dta_calc %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\ndta_calc\n```\n3. Tahap 3 dan 4 akan kita buat dalam iterasi di R dengan memanfaatkan coding diatas\n\n\n```{r}\n## input data ke R\ndta <- read.table(header = TRUE,\n           text =\"Tip\tCoupon\tResponse\n1\t1\t9.3\n2\t1\t9.4\n3\t1\tNA\n4\t1\t9.7\n1\t2\t9.4\n2\t2\t9.3\n3\t2\t9.4\n4\t2\t9.6\n1\t3\t9.6\n2\t3\t9.8\n3\t3\t9.5\n4\t3\t10\n1\t4\t10\n2\t4\t9.9\n3\t4\t9.7\n4\t4\tNA\n\" )\nglimpse(dta)\n```\n\nBerikutnya kita mulai EM-algorithm. \n\nPada bagian ini akan diilustrasikan missing data akan diganti dengan nilai awal dibandingkan dengan nilai estimasi yang didapatkan dari parameter seperti ilustrasi sebelumnya.\n\n```{r}\n# menambahkan kolom dengan informasi missing data\ndta <- dta %>%  mutate(is_miss = ifelse(is.na(Response),\"miss\",\"not\")\n                       )\n\n## Menghitung estimasi parameter dengan nilai awal 2 \n\n dta <- dta %>% \n  mutate( Response = ifelse(is_miss==\"miss\",\n                            2,\n                            Response)\n  )\n\nmu_hat0 = dta %>% \n  summarise(mean(Response)) %>% \n  pull()\n\nalpha_hat0 <- dta %>% \n  group_by(Tip) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\n\nbeta_hat0 <- dta %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\n\n# memasukan hasil estimasi paramater ke dalam data.frame\ndta_calc <- dta %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\n\n# nilai estimasi missing data\nymiss_rec <- dta_calc %>% \n  filter(is_miss==\"miss\")\n\n# y_missing nilai awal 2\nymiss =c(2,2)\nres_table <- data.frame(iter=0,\n           name_ymiss=c(\"y31\",\"y44\"),\n           ymiss=ymiss,\n           mu_hat = ymiss_rec %>% pull(mu_hat),\n           alpha_hat = ymiss_rec %>% pull(alpha_hat),\n           beta_hat = ymiss_rec %>% pull(beta_hat)\n           )\ntol <- 1e-7\n\nfor (i in 1:100){\n  \n\n# input nilai estimasi missing data\ndta_calc <- dta_calc %>% \n  mutate(Response = ifelse(is_miss==\"miss\",\n                           ymiss,\n                           Response)\n         )\n\nmu_hat0 = dta_calc %>% \n  summarise(mean(Response)) %>% \n  pull()\n\n\nalpha_hat0 <- dta_calc %>% \n  group_by(Tip) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\n\nbeta_hat0 <- dta_calc %>% \n  group_by(Coupon) %>% \n  summarise(mean(Response)) %>% \n  pull() - mu_hat0\n\ndta_calc <- dta_calc %>% \n  mutate(mu_hat = mu_hat0) %>% \n  group_by(Coupon) %>% \n  mutate(alpha_hat = alpha_hat0) %>% \n  ungroup() %>% \n  group_by(Tip) %>% \n  mutate(beta_hat = beta_hat0) %>% \n  ungroup()\n\n\n# nilai estimasi missing data\nymiss_rec <- dta_calc %>% \n  filter(is_miss==\"miss\") %>%\n  mutate( ymiss = mu_hat+alpha_hat+beta_hat)\n  \nymiss_old <- ymiss\nymiss <- ymiss_rec %>%  pull(ymiss)\n\nres_table <- rbind(res_table,data.frame(iter=i,\n           name_ymiss=c(\"y31\",\"y44\"),\n           ymiss=ymiss,\n           mu_hat = ymiss_rec %>% pull(mu_hat),\n           alpha_hat = ymiss_rec %>% pull(alpha_hat),\n           beta_hat = ymiss_rec %>% pull(beta_hat)\n           ))\nif(all(abs(ymiss_old-ymiss)<=tol)){\n  break\n}\n\n}\n```\n\nHasil akhir yang diperoleh\n\n```{r}\nres_table\n```\n\n\n\n## Referensi\n\nHogg, Robert V., Joseph W. McKean, and Allen T,Craig.2013. Introduction to Mathematical Statistics. 7th ed. Boston: Pearson.\n\nhttps://www.statisticshowto.com/em-algorithm-expectation-maximization/"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"html-math-method":{"method":"mathjax","url":"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js","embed-resources":true,"toc":true,"toc-depth":6},"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":{"light":"flatly","dark":"darkly"},"page-layout":"article","comments":{"hypothesis":{"theme":"clean","openSidebar":false}},"title":"Algoritme Expectation-Maximization (EM) menggunakan R","date":"11-19-2021","author":"Gerry Alfa Dito","categories":["R Programming","Computational Statistics"],"draft":false,"image":"post-image.jpg"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}